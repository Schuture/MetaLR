Please install apex for mixed precision training from: https://github.com/NVIDIA/apex

Running on: cuda
The device name is: NVIDIA RTX A6000
The capability of this device is: (8, 6) 

State dict path: pretrained/best_model.pth

=================Evaluation on POCUS dataset start===================

random seed: 0

====================The training of fold 1 start.====================

The self-supervised trained parameters are loaded.


Training start!

Training:Epoch[001/030] Iteration[002/014] Loss: 0.8164 Acc:65.23% Time:0.4955s
Training:Epoch[001/030] Iteration[004/014] Loss: 0.2512 Acc:78.91% Time:0.3744s
Training:Epoch[001/030] Iteration[006/014] Loss: 0.2238 Acc:83.33% Time:0.3744s
Training:Epoch[001/030] Iteration[008/014] Loss: 0.1501 Acc:86.33% Time:0.3809s
Training:Epoch[001/030] Iteration[010/014] Loss: 0.2310 Acc:88.20% Time:0.3705s
Training:Epoch[001/030] Iteration[012/014] Loss: 0.1340 Acc:89.58% Time:0.3682s
Training:Epoch[001/030] Iteration[014/014] Loss: 0.0913 Acc:90.33% Time:0.4002s
Test:	 Epoch[001/030] Iteration[003/003] Acc:75.34%

The learning rate for epoch 1 is [0.001565, 0.000971, 0.000979, 0.000961, 0.000981, 0.00092, 0.000944, 0.000877, 0.001013, 0.01]
Training:Epoch[002/030] Iteration[002/014] Loss: 0.0432 Acc:98.83% Time:0.3726s
Training:Epoch[002/030] Iteration[004/014] Loss: 0.0565 Acc:98.24% Time:0.3678s
Training:Epoch[002/030] Iteration[006/014] Loss: 0.0958 Acc:98.05% Time:0.3868s
Training:Epoch[002/030] Iteration[008/014] Loss: 0.0904 Acc:97.95% Time:0.3733s
Training:Epoch[002/030] Iteration[010/014] Loss: 0.0446 Acc:97.97% Time:0.3648s
Training:Epoch[002/030] Iteration[012/014] Loss: 0.1172 Acc:97.92% Time:0.3618s
Training:Epoch[002/030] Iteration[014/014] Loss: 0.0482 Acc:98.05% Time:0.3756s
Test:	 Epoch[002/030] Iteration[003/003] Acc:63.41%

The learning rate for epoch 2 is [0.001413, 0.000909, 0.000949, 0.000943, 0.000973, 0.000909, 0.000921, 0.000862, 0.001007, 0.01]
Training:Epoch[003/030] Iteration[002/014] Loss: 0.0830 Acc:97.66% Time:0.3825s
Training:Epoch[003/030] Iteration[004/014] Loss: 0.0848 Acc:97.46% Time:0.3368s
Training:Epoch[003/030] Iteration[006/014] Loss: 0.0453 Acc:97.79% Time:0.3671s
Training:Epoch[003/030] Iteration[008/014] Loss: 0.0478 Acc:97.95% Time:0.3714s
Training:Epoch[003/030] Iteration[010/014] Loss: 0.0429 Acc:98.05% Time:0.3861s
Training:Epoch[003/030] Iteration[012/014] Loss: 0.0562 Acc:98.11% Time:0.4093s
Training:Epoch[003/030] Iteration[014/014] Loss: 0.1726 Acc:97.88% Time:0.4042s
Test:	 Epoch[003/030] Iteration[003/003] Acc:78.86%

The learning rate for epoch 3 is [0.001524, 0.000932, 0.000961, 0.000971, 0.001006, 0.000954, 0.000946, 0.000877, 0.00101, 0.01]
Training:Epoch[004/030] Iteration[002/014] Loss: 0.0135 Acc:100.00% Time:0.3799s
Training:Epoch[004/030] Iteration[004/014] Loss: 0.0246 Acc:99.61% Time:0.3705s
Training:Epoch[004/030] Iteration[006/014] Loss: 0.0623 Acc:99.35% Time:0.3731s
Training:Epoch[004/030] Iteration[008/014] Loss: 0.0737 Acc:98.63% Time:0.4243s
Training:Epoch[004/030] Iteration[010/014] Loss: 0.0562 Acc:98.44% Time:0.3689s
Training:Epoch[004/030] Iteration[012/014] Loss: 0.0297 Acc:98.50% Time:0.3847s
Training:Epoch[004/030] Iteration[014/014] Loss: 0.0275 Acc:98.57% Time:0.3941s
Test:	 Epoch[004/030] Iteration[003/003] Acc:60.98%

The learning rate for epoch 4 is [0.001436, 0.000917, 0.000957, 0.000949, 0.000974, 0.000934, 0.000938, 0.000867, 0.001011, 0.01]
Training:Epoch[005/030] Iteration[002/014] Loss: 0.0219 Acc:99.61% Time:0.3747s
Training:Epoch[005/030] Iteration[004/014] Loss: 0.0739 Acc:99.22% Time:0.3535s
Training:Epoch[005/030] Iteration[006/014] Loss: 0.0152 Acc:99.35% Time:0.3848s
Training:Epoch[005/030] Iteration[008/014] Loss: 0.0166 Acc:99.32% Time:0.3855s
Training:Epoch[005/030] Iteration[010/014] Loss: 0.0343 Acc:99.22% Time:0.3791s
Training:Epoch[005/030] Iteration[012/014] Loss: 0.0545 Acc:99.02% Time:0.3705s
Training:Epoch[005/030] Iteration[014/014] Loss: 0.0250 Acc:98.97% Time:0.3916s
Test:	 Epoch[005/030] Iteration[003/003] Acc:71.82%

The learning rate for epoch 5 is [0.001467, 0.00095, 0.000963, 0.000974, 0.000986, 0.000946, 0.000946, 0.00088, 0.001015, 0.01]
Training:Epoch[006/030] Iteration[002/014] Loss: 0.0432 Acc:98.05% Time:0.3718s
Training:Epoch[006/030] Iteration[004/014] Loss: 0.0294 Acc:98.63% Time:0.3636s
Training:Epoch[006/030] Iteration[006/014] Loss: 0.0629 Acc:98.18% Time:0.3706s
Training:Epoch[006/030] Iteration[008/014] Loss: 0.0899 Acc:97.75% Time:0.3702s
Training:Epoch[006/030] Iteration[010/014] Loss: 0.0136 Acc:98.12% Time:0.3827s
Training:Epoch[006/030] Iteration[012/014] Loss: 0.0377 Acc:98.11% Time:0.3779s
Training:Epoch[006/030] Iteration[014/014] Loss: 0.0415 Acc:98.17% Time:0.3936s
Test:	 Epoch[006/030] Iteration[003/003] Acc:85.64%

The learning rate for epoch 6 is [0.001481, 0.000878, 0.000923, 0.000931, 0.000936, 0.000906, 0.000928, 0.000875, 0.001022, 0.009254]
Training:Epoch[007/030] Iteration[002/014] Loss: 0.0291 Acc:98.83% Time:0.3871s
Training:Epoch[007/030] Iteration[004/014] Loss: 0.0824 Acc:98.83% Time:0.3859s
Training:Epoch[007/030] Iteration[006/014] Loss: 0.0169 Acc:99.09% Time:0.3837s
Training:Epoch[007/030] Iteration[008/014] Loss: 0.0230 Acc:99.12% Time:0.4525s
Training:Epoch[007/030] Iteration[010/014] Loss: 0.0267 Acc:99.14% Time:0.3697s
Training:Epoch[007/030] Iteration[012/014] Loss: 0.0376 Acc:99.02% Time:0.4405s
Training:Epoch[007/030] Iteration[014/014] Loss: 0.0121 Acc:99.08% Time:0.3874s
Test:	 Epoch[007/030] Iteration[003/003] Acc:70.46%

The learning rate for epoch 7 is [0.001434, 0.000834, 0.000894, 0.000895, 0.000913, 0.000909, 0.000936, 0.000883, 0.001027, 0.009159]
Training:Epoch[008/030] Iteration[002/014] Loss: 0.0029 Acc:100.00% Time:0.3847s
Training:Epoch[008/030] Iteration[004/014] Loss: 0.0102 Acc:99.80% Time:0.3855s
Training:Epoch[008/030] Iteration[006/014] Loss: 0.0085 Acc:99.74% Time:0.3715s
Training:Epoch[008/030] Iteration[008/014] Loss: 0.0190 Acc:99.71% Time:0.4213s
Training:Epoch[008/030] Iteration[010/014] Loss: 0.0074 Acc:99.77% Time:0.3702s
Training:Epoch[008/030] Iteration[012/014] Loss: 0.0063 Acc:99.74% Time:0.3754s
Training:Epoch[008/030] Iteration[014/014] Loss: 0.0143 Acc:99.71% Time:0.3648s
Test:	 Epoch[008/030] Iteration[003/003] Acc:80.49%

The learning rate for epoch 8 is [0.001428, 0.000823, 0.000888, 0.000883, 0.00091, 0.000903, 0.000935, 0.000883, 0.001029, 0.009575]
Training:Epoch[009/030] Iteration[002/014] Loss: 0.0080 Acc:99.61% Time:0.3740s
Training:Epoch[009/030] Iteration[004/014] Loss: 0.0020 Acc:99.80% Time:0.3642s
Training:Epoch[009/030] Iteration[006/014] Loss: 0.0257 Acc:99.74% Time:0.3881s
Training:Epoch[009/030] Iteration[008/014] Loss: 0.0088 Acc:99.71% Time:0.3761s
Training:Epoch[009/030] Iteration[010/014] Loss: 0.0038 Acc:99.77% Time:0.3869s
Training:Epoch[009/030] Iteration[012/014] Loss: 0.0340 Acc:99.67% Time:0.3838s
Training:Epoch[009/030] Iteration[014/014] Loss: 0.0006 Acc:99.71% Time:0.3744s
Test:	 Epoch[009/030] Iteration[003/003] Acc:85.37%

The learning rate for epoch 9 is [0.001447, 0.000819, 0.000883, 0.000885, 0.000911, 0.000905, 0.000934, 0.000882, 0.001026, 0.009628]
Training:Epoch[010/030] Iteration[002/014] Loss: 0.0101 Acc:99.61% Time:0.3740s
Training:Epoch[010/030] Iteration[004/014] Loss: 0.0138 Acc:99.41% Time:0.3901s
Training:Epoch[010/030] Iteration[006/014] Loss: 0.0024 Acc:99.61% Time:0.3862s
Training:Epoch[010/030] Iteration[008/014] Loss: 0.0220 Acc:99.51% Time:0.3554s
Training:Epoch[010/030] Iteration[010/014] Loss: 0.0032 Acc:99.61% Time:0.3841s
Training:Epoch[010/030] Iteration[012/014] Loss: 0.0016 Acc:99.67% Time:0.3754s
Training:Epoch[010/030] Iteration[014/014] Loss: 0.0377 Acc:99.66% Time:0.3626s
Test:	 Epoch[010/030] Iteration[003/003] Acc:78.86%

The learning rate for epoch 10 is [0.001414, 0.000846, 0.000901, 0.000906, 0.000912, 0.000901, 0.000934, 0.000877, 0.001024, 0.009751]
Training:Epoch[011/030] Iteration[002/014] Loss: 0.0134 Acc:99.61% Time:0.3809s
Training:Epoch[011/030] Iteration[004/014] Loss: 0.0083 Acc:99.61% Time:0.3815s
Training:Epoch[011/030] Iteration[006/014] Loss: 0.0230 Acc:99.48% Time:0.3663s
Training:Epoch[011/030] Iteration[008/014] Loss: 0.0873 Acc:99.02% Time:0.3754s
Training:Epoch[011/030] Iteration[010/014] Loss: 0.0415 Acc:98.98% Time:0.3768s
Training:Epoch[011/030] Iteration[012/014] Loss: 0.0105 Acc:99.09% Time:0.3738s
Training:Epoch[011/030] Iteration[014/014] Loss: 0.0178 Acc:99.14% Time:0.4041s
Test:	 Epoch[011/030] Iteration[003/003] Acc:79.13%

The learning rate for epoch 11 is [0.001437, 0.000841, 0.00091, 0.000916, 0.000915, 0.000909, 0.000934, 0.000877, 0.001021, 0.008844]
Training:Epoch[012/030] Iteration[002/014] Loss: 0.0153 Acc:100.00% Time:0.3696s
Training:Epoch[012/030] Iteration[004/014] Loss: 0.0065 Acc:99.80% Time:0.3617s
Training:Epoch[012/030] Iteration[006/014] Loss: 0.0099 Acc:99.74% Time:0.3744s
Training:Epoch[012/030] Iteration[008/014] Loss: 0.0026 Acc:99.80% Time:0.3846s
Training:Epoch[012/030] Iteration[010/014] Loss: 0.0274 Acc:99.69% Time:0.3839s
Training:Epoch[012/030] Iteration[012/014] Loss: 0.0403 Acc:99.48% Time:0.3932s
Training:Epoch[012/030] Iteration[014/014] Loss: 0.0165 Acc:99.48% Time:0.3925s
Test:	 Epoch[012/030] Iteration[003/003] Acc:75.34%

The learning rate for epoch 12 is [0.001406, 0.000828, 0.000911, 0.00092, 0.000911, 0.0009, 0.000933, 0.000878, 0.001025, 0.009493]
Training:Epoch[013/030] Iteration[002/014] Loss: 0.0182 Acc:99.61% Time:0.3731s
Training:Epoch[013/030] Iteration[004/014] Loss: 0.0017 Acc:99.80% Time:0.3736s
Training:Epoch[013/030] Iteration[006/014] Loss: 0.0136 Acc:99.61% Time:0.3773s
Training:Epoch[013/030] Iteration[008/014] Loss: 0.0765 Acc:99.12% Time:0.3717s
Training:Epoch[013/030] Iteration[010/014] Loss: 0.0138 Acc:99.22% Time:0.3856s
Training:Epoch[013/030] Iteration[012/014] Loss: 0.0146 Acc:99.28% Time:0.3828s
Training:Epoch[013/030] Iteration[014/014] Loss: 0.1473 Acc:99.08% Time:0.4025s
Test:	 Epoch[013/030] Iteration[003/003] Acc:76.69%

The learning rate for epoch 13 is [0.00137, 0.000839, 0.000884, 0.000891, 0.000891, 0.000884, 0.000922, 0.000863, 0.001017, 0.009586]
Training:Epoch[014/030] Iteration[002/014] Loss: 0.0623 Acc:98.05% Time:0.3957s
Training:Epoch[014/030] Iteration[004/014] Loss: 0.0992 Acc:97.46% Time:0.3854s
Training:Epoch[014/030] Iteration[006/014] Loss: 0.0266 Acc:97.92% Time:0.3858s
Training:Epoch[014/030] Iteration[008/014] Loss: 0.0203 Acc:98.34% Time:0.3816s
Training:Epoch[014/030] Iteration[010/014] Loss: 0.0787 Acc:98.44% Time:0.3940s
Training:Epoch[014/030] Iteration[012/014] Loss: 0.0534 Acc:98.50% Time:0.3855s
Training:Epoch[014/030] Iteration[014/014] Loss: 0.1081 Acc:98.28% Time:0.4241s
Test:	 Epoch[014/030] Iteration[003/003] Acc:50.14%

The learning rate for epoch 14 is [0.001237, 0.00076, 0.000873, 0.000762, 0.000844, 0.000838, 0.000917, 0.000858, 0.001015, 0.008976]
Training:Epoch[015/030] Iteration[002/014] Loss: 0.0317 Acc:99.61% Time:0.3655s
Training:Epoch[015/030] Iteration[004/014] Loss: 0.0220 Acc:99.61% Time:0.3810s
Training:Epoch[015/030] Iteration[006/014] Loss: 0.0099 Acc:99.74% Time:0.3813s
Training:Epoch[015/030] Iteration[008/014] Loss: 0.0085 Acc:99.71% Time:0.3907s
Training:Epoch[015/030] Iteration[010/014] Loss: 0.0272 Acc:99.53% Time:0.3789s
Training:Epoch[015/030] Iteration[012/014] Loss: 0.0371 Acc:99.35% Time:0.3813s
Training:Epoch[015/030] Iteration[014/014] Loss: 0.0430 Acc:99.26% Time:0.3544s
Test:	 Epoch[015/030] Iteration[003/003] Acc:79.13%

The learning rate for epoch 15 is [0.001431, 0.000897, 0.000957, 0.000789, 0.000851, 0.000848, 0.00092, 0.000858, 0.00102, 0.009206]
Training:Epoch[016/030] Iteration[002/014] Loss: 0.0137 Acc:99.61% Time:0.3696s
Training:Epoch[016/030] Iteration[004/014] Loss: 0.0241 Acc:99.61% Time:0.3762s
Training:Epoch[016/030] Iteration[006/014] Loss: 0.0329 Acc:99.61% Time:0.3831s
Training:Epoch[016/030] Iteration[008/014] Loss: 0.0394 Acc:99.41% Time:0.3855s
Training:Epoch[016/030] Iteration[010/014] Loss: 0.0436 Acc:99.30% Time:0.3757s
Training:Epoch[016/030] Iteration[012/014] Loss: 0.0206 Acc:99.22% Time:0.3850s
Training:Epoch[016/030] Iteration[014/014] Loss: 0.0163 Acc:99.26% Time:0.4024s
Test:	 Epoch[016/030] Iteration[003/003] Acc:79.13%

The learning rate for epoch 16 is [0.001379, 0.000905, 0.000967, 0.000801, 0.000882, 0.000859, 0.000921, 0.000861, 0.001022, 0.008804]
Training:Epoch[017/030] Iteration[002/014] Loss: 0.0039 Acc:100.00% Time:0.3843s
Training:Epoch[017/030] Iteration[004/014] Loss: 0.0254 Acc:99.41% Time:0.3742s
Training:Epoch[017/030] Iteration[006/014] Loss: 0.0096 Acc:99.48% Time:0.3822s
Training:Epoch[017/030] Iteration[008/014] Loss: 0.0279 Acc:99.32% Time:0.3910s
Training:Epoch[017/030] Iteration[010/014] Loss: 0.0408 Acc:99.22% Time:0.3859s
Training:Epoch[017/030] Iteration[012/014] Loss: 0.0146 Acc:99.22% Time:0.3840s
Training:Epoch[017/030] Iteration[014/014] Loss: 0.0334 Acc:99.14% Time:0.3992s
Test:	 Epoch[017/030] Iteration[003/003] Acc:70.73%

The learning rate for epoch 17 is [0.001586, 0.001001, 0.001006, 0.000832, 0.000884, 0.000867, 0.000925, 0.000863, 0.001024, 0.008944]
Training:Epoch[018/030] Iteration[002/014] Loss: 0.0238 Acc:99.61% Time:0.3663s
Training:Epoch[018/030] Iteration[004/014] Loss: 0.0383 Acc:99.41% Time:0.3855s
Training:Epoch[018/030] Iteration[006/014] Loss: 0.0200 Acc:99.48% Time:0.3805s
Training:Epoch[018/030] Iteration[008/014] Loss: 0.0083 Acc:99.51% Time:0.3751s
Training:Epoch[018/030] Iteration[010/014] Loss: 0.0059 Acc:99.61% Time:0.3717s
Training:Epoch[018/030] Iteration[012/014] Loss: 0.0087 Acc:99.61% Time:0.3881s
Training:Epoch[018/030] Iteration[014/014] Loss: 0.0044 Acc:99.66% Time:0.3909s
Test:	 Epoch[018/030] Iteration[003/003] Acc:79.40%

The learning rate for epoch 18 is [0.00163, 0.001033, 0.001024, 0.000858, 0.000897, 0.000878, 0.000928, 0.000866, 0.001024, 0.009104]
Training:Epoch[019/030] Iteration[002/014] Loss: 0.0127 Acc:99.61% Time:0.3839s
Training:Epoch[019/030] Iteration[004/014] Loss: 0.0055 Acc:99.80% Time:0.3742s
Training:Epoch[019/030] Iteration[006/014] Loss: 0.0046 Acc:99.74% Time:0.3684s
Training:Epoch[019/030] Iteration[008/014] Loss: 0.0036 Acc:99.80% Time:0.3713s
Training:Epoch[019/030] Iteration[010/014] Loss: 0.0047 Acc:99.77% Time:0.3847s
Training:Epoch[019/030] Iteration[012/014] Loss: 0.0006 Acc:99.80% Time:0.3831s
Training:Epoch[019/030] Iteration[014/014] Loss: 0.0256 Acc:99.71% Time:0.4064s
Test:	 Epoch[019/030] Iteration[003/003] Acc:71.27%

The learning rate for epoch 19 is [0.001595, 0.001015, 0.001018, 0.000849, 0.000889, 0.000867, 0.000923, 0.000861, 0.001023, 0.009202]
Training:Epoch[020/030] Iteration[002/014] Loss: 0.0163 Acc:99.22% Time:0.3830s
Training:Epoch[020/030] Iteration[004/014] Loss: 0.0005 Acc:99.61% Time:0.3844s
Training:Epoch[020/030] Iteration[006/014] Loss: 0.0106 Acc:99.48% Time:0.3835s
Training:Epoch[020/030] Iteration[008/014] Loss: 0.0345 Acc:99.32% Time:0.3708s
Training:Epoch[020/030] Iteration[010/014] Loss: 0.0070 Acc:99.45% Time:0.3865s
Training:Epoch[020/030] Iteration[012/014] Loss: 0.0740 Acc:99.15% Time:0.3826s
Training:Epoch[020/030] Iteration[014/014] Loss: 0.0098 Acc:99.26% Time:0.3756s
Test:	 Epoch[020/030] Iteration[003/003] Acc:71.82%

The learning rate for epoch 20 is [0.001583, 0.000931, 0.001002, 0.000866, 0.000886, 0.000861, 0.000913, 0.000859, 0.001022, 0.009286]
Training:Epoch[021/030] Iteration[002/014] Loss: 0.0087 Acc:100.00% Time:0.4131s
Training:Epoch[021/030] Iteration[004/014] Loss: 0.0103 Acc:99.80% Time:0.3826s
Training:Epoch[021/030] Iteration[006/014] Loss: 0.0166 Acc:99.48% Time:0.3823s
Training:Epoch[021/030] Iteration[008/014] Loss: 0.0111 Acc:99.51% Time:0.3842s
Training:Epoch[021/030] Iteration[010/014] Loss: 0.0149 Acc:99.45% Time:0.3836s
Training:Epoch[021/030] Iteration[012/014] Loss: 0.0308 Acc:99.48% Time:0.4395s
Training:Epoch[021/030] Iteration[014/014] Loss: 0.0328 Acc:99.37% Time:0.3897s
Test:	 Epoch[021/030] Iteration[003/003] Acc:71.54%

The learning rate for epoch 21 is [0.00166, 0.000848, 0.000978, 0.000846, 0.000873, 0.00086, 0.000913, 0.00086, 0.001022, 0.009084]
Training:Epoch[022/030] Iteration[002/014] Loss: 0.0100 Acc:99.61% Time:0.3855s
Training:Epoch[022/030] Iteration[004/014] Loss: 0.0056 Acc:99.61% Time:0.3854s
Training:Epoch[022/030] Iteration[006/014] Loss: 0.0183 Acc:99.48% Time:0.3734s
Training:Epoch[022/030] Iteration[008/014] Loss: 0.0052 Acc:99.51% Time:0.3906s
Training:Epoch[022/030] Iteration[010/014] Loss: 0.0085 Acc:99.53% Time:0.3930s
Training:Epoch[022/030] Iteration[012/014] Loss: 0.0104 Acc:99.54% Time:0.3745s
Training:Epoch[022/030] Iteration[014/014] Loss: 0.0693 Acc:99.43% Time:0.3786s
Test:	 Epoch[022/030] Iteration[003/003] Acc:67.75%

The learning rate for epoch 22 is [0.001506, 0.000799, 0.000958, 0.000811, 0.000857, 0.000844, 0.000903, 0.000854, 0.001021, 0.009184]
Training:Epoch[023/030] Iteration[002/014] Loss: 0.0157 Acc:99.22% Time:0.3757s
Training:Epoch[023/030] Iteration[004/014] Loss: 0.0374 Acc:98.83% Time:0.3901s
Training:Epoch[023/030] Iteration[006/014] Loss: 0.0628 Acc:98.44% Time:0.3778s
Training:Epoch[023/030] Iteration[008/014] Loss: 0.0745 Acc:98.05% Time:0.3673s
Training:Epoch[023/030] Iteration[010/014] Loss: 0.0159 Acc:98.36% Time:0.3833s
Training:Epoch[023/030] Iteration[012/014] Loss: 0.0231 Acc:98.50% Time:0.3709s
Training:Epoch[023/030] Iteration[014/014] Loss: 0.0056 Acc:98.68% Time:0.4084s
Test:	 Epoch[023/030] Iteration[003/003] Acc:77.24%

The learning rate for epoch 23 is [0.001072, 0.000522, 0.000834, 0.000701, 0.000793, 0.000804, 0.000899, 0.000846, 0.00102, 0.008796]
Training:Epoch[024/030] Iteration[002/014] Loss: 0.0098 Acc:99.61% Time:0.3770s
Training:Epoch[024/030] Iteration[004/014] Loss: 0.0105 Acc:99.80% Time:0.3869s
Training:Epoch[024/030] Iteration[006/014] Loss: 0.0125 Acc:99.74% Time:0.3225s
Training:Epoch[024/030] Iteration[008/014] Loss: 0.0069 Acc:99.80% Time:0.3857s
Training:Epoch[024/030] Iteration[010/014] Loss: 0.0110 Acc:99.77% Time:0.3833s
Training:Epoch[024/030] Iteration[012/014] Loss: 0.0092 Acc:99.74% Time:0.3820s
Training:Epoch[024/030] Iteration[014/014] Loss: 0.0056 Acc:99.77% Time:0.3876s
Test:	 Epoch[024/030] Iteration[003/003] Acc:78.59%

The learning rate for epoch 24 is [0.001054, 0.000511, 0.000828, 0.000688, 0.000784, 0.000798, 0.000896, 0.000843, 0.00102, 0.009017]
Training:Epoch[025/030] Iteration[002/014] Loss: 0.0014 Acc:100.00% Time:0.3967s
Training:Epoch[025/030] Iteration[004/014] Loss: 0.0113 Acc:99.80% Time:0.3684s
Training:Epoch[025/030] Iteration[006/014] Loss: 0.0005 Acc:99.87% Time:0.4368s
Training:Epoch[025/030] Iteration[008/014] Loss: 0.0030 Acc:99.90% Time:0.3857s
Training:Epoch[025/030] Iteration[010/014] Loss: 0.0002 Acc:99.92% Time:0.3881s
Training:Epoch[025/030] Iteration[012/014] Loss: 0.0004 Acc:99.93% Time:0.3846s
Training:Epoch[025/030] Iteration[014/014] Loss: 0.0232 Acc:99.83% Time:0.4036s
Test:	 Epoch[025/030] Iteration[003/003] Acc:80.49%

The learning rate for epoch 25 is [0.00104, 0.000487, 0.000799, 0.000653, 0.000759, 0.000778, 0.000886, 0.000834, 0.001017, 0.008906]
Training:Epoch[026/030] Iteration[002/014] Loss: 0.0004 Acc:100.00% Time:0.4283s
Training:Epoch[026/030] Iteration[004/014] Loss: 0.0002 Acc:100.00% Time:0.3854s
Training:Epoch[026/030] Iteration[006/014] Loss: 0.0039 Acc:100.00% Time:0.3669s
Training:Epoch[026/030] Iteration[008/014] Loss: 0.0061 Acc:99.90% Time:0.3853s
Training:Epoch[026/030] Iteration[010/014] Loss: 0.0151 Acc:99.77% Time:0.3875s
Training:Epoch[026/030] Iteration[012/014] Loss: 0.0201 Acc:99.74% Time:0.3856s
Training:Epoch[026/030] Iteration[014/014] Loss: 0.0085 Acc:99.71% Time:0.3524s
Test:	 Epoch[026/030] Iteration[003/003] Acc:75.07%

The learning rate for epoch 26 is [0.001048, 0.00048, 0.000791, 0.000644, 0.000748, 0.000773, 0.00088, 0.000841, 0.00102, 0.009065]
Training:Epoch[027/030] Iteration[002/014] Loss: 0.0084 Acc:99.61% Time:0.3733s
Training:Epoch[027/030] Iteration[004/014] Loss: 0.0007 Acc:99.80% Time:0.3830s
Training:Epoch[027/030] Iteration[006/014] Loss: 0.0228 Acc:99.74% Time:0.3702s
Training:Epoch[027/030] Iteration[008/014] Loss: 0.0029 Acc:99.80% Time:0.3814s
Training:Epoch[027/030] Iteration[010/014] Loss: 0.0093 Acc:99.69% Time:0.3846s
Training:Epoch[027/030] Iteration[012/014] Loss: 0.0062 Acc:99.67% Time:0.3858s
Training:Epoch[027/030] Iteration[014/014] Loss: 0.0006 Acc:99.71% Time:0.3693s
Test:	 Epoch[027/030] Iteration[003/003] Acc:76.42%

The learning rate for epoch 27 is [0.001036, 0.000458, 0.000775, 0.000619, 0.000742, 0.000767, 0.000877, 0.000838, 0.001019, 0.008889]
Training:Epoch[028/030] Iteration[002/014] Loss: 0.0005 Acc:100.00% Time:0.3695s
Training:Epoch[028/030] Iteration[004/014] Loss: 0.0056 Acc:99.80% Time:0.3695s
Training:Epoch[028/030] Iteration[006/014] Loss: 0.0013 Acc:99.87% Time:0.3858s
Training:Epoch[028/030] Iteration[008/014] Loss: 0.0023 Acc:99.90% Time:0.3770s
Training:Epoch[028/030] Iteration[010/014] Loss: 0.0090 Acc:99.84% Time:0.3864s
Training:Epoch[028/030] Iteration[012/014] Loss: 0.0018 Acc:99.87% Time:0.3931s
Training:Epoch[028/030] Iteration[014/014] Loss: 0.0003 Acc:99.89% Time:0.3718s
Test:	 Epoch[028/030] Iteration[003/003] Acc:76.42%

The learning rate for epoch 28 is [0.001053, 0.000481, 0.000794, 0.000636, 0.000761, 0.000782, 0.000881, 0.000841, 0.001018, 0.008864]
Training:Epoch[029/030] Iteration[002/014] Loss: 0.0025 Acc:100.00% Time:0.3819s
Training:Epoch[029/030] Iteration[004/014] Loss: 0.0013 Acc:100.00% Time:0.3656s
Training:Epoch[029/030] Iteration[006/014] Loss: 0.0004 Acc:100.00% Time:0.3877s
Training:Epoch[029/030] Iteration[008/014] Loss: 0.0003 Acc:100.00% Time:0.3846s
Training:Epoch[029/030] Iteration[010/014] Loss: 0.0005 Acc:100.00% Time:0.3966s
Training:Epoch[029/030] Iteration[012/014] Loss: 0.0003 Acc:100.00% Time:0.3889s
Training:Epoch[029/030] Iteration[014/014] Loss: 0.0097 Acc:99.94% Time:0.3807s
Test:	 Epoch[029/030] Iteration[003/003] Acc:73.17%

The learning rate for epoch 29 is [0.001051, 0.000479, 0.00079, 0.000637, 0.000764, 0.000786, 0.000882, 0.000841, 0.001018, 0.009023]
Training:Epoch[030/030] Iteration[002/014] Loss: 0.0003 Acc:100.00% Time:0.4310s
Training:Epoch[030/030] Iteration[004/014] Loss: 0.0058 Acc:99.80% Time:0.3851s
Training:Epoch[030/030] Iteration[006/014] Loss: 0.0243 Acc:99.61% Time:0.3734s
Training:Epoch[030/030] Iteration[008/014] Loss: 0.0001 Acc:99.71% Time:0.3747s
Training:Epoch[030/030] Iteration[010/014] Loss: 0.0064 Acc:99.69% Time:0.3957s
Training:Epoch[030/030] Iteration[012/014] Loss: 0.0004 Acc:99.74% Time:0.3847s
Training:Epoch[030/030] Iteration[014/014] Loss: 0.0245 Acc:99.71% Time:0.3922s
Test:	 Epoch[030/030] Iteration[003/003] Acc:71.27%

The learning rate for epoch 30 is [0.001052, 0.00048, 0.000788, 0.00063, 0.000761, 0.000781, 0.00088, 0.00084, 0.001018, 0.00885]

Training finish, the time consumption of 30 epochs is 243s

The max testing accuracy is: 85.64%, reached at epoch 6.


====================The training of fold 2 start.====================

The self-supervised trained parameters are loaded.


Training start!

Training:Epoch[001/030] Iteration[002/013] Loss: 0.9671 Acc:51.95% Time:0.3668s
Training:Epoch[001/030] Iteration[004/013] Loss: 0.4446 Acc:67.19% Time:0.3763s
Training:Epoch[001/030] Iteration[006/013] Loss: 0.2242 Acc:75.91% Time:0.3738s
Training:Epoch[001/030] Iteration[008/013] Loss: 0.1865 Acc:80.66% Time:0.3533s
Training:Epoch[001/030] Iteration[010/013] Loss: 0.2460 Acc:83.20% Time:0.3676s
Training:Epoch[001/030] Iteration[012/013] Loss: 0.1599 Acc:85.16% Time:0.3843s
Test:	 Epoch[001/030] Iteration[004/004] Acc:80.90%

The learning rate for epoch 1 is [0.000913, 0.001031, 0.001025, 0.001022, 0.000983, 0.000965, 0.000949, 0.000925, 0.000897, 0.01]
Training:Epoch[002/030] Iteration[002/013] Loss: 0.1361 Acc:96.09% Time:0.3874s
Training:Epoch[002/030] Iteration[004/013] Loss: 0.1130 Acc:95.90% Time:0.3885s
Training:Epoch[002/030] Iteration[006/013] Loss: 0.1042 Acc:96.35% Time:0.3830s
Training:Epoch[002/030] Iteration[008/013] Loss: 0.0601 Acc:96.68% Time:0.3677s
Training:Epoch[002/030] Iteration[010/013] Loss: 0.0971 Acc:96.80% Time:0.3758s
Training:Epoch[002/030] Iteration[012/013] Loss: 0.0712 Acc:96.74% Time:0.4554s
Test:	 Epoch[002/030] Iteration[004/004] Acc:83.98%

The learning rate for epoch 2 is [0.000735, 0.001013, 0.001025, 0.001014, 0.000978, 0.000942, 0.000951, 0.000896, 0.000864, 0.01]
Training:Epoch[003/030] Iteration[002/013] Loss: 0.1461 Acc:96.48% Time:0.3814s
Training:Epoch[003/030] Iteration[004/013] Loss: 0.0913 Acc:96.88% Time:0.3891s
Training:Epoch[003/030] Iteration[006/013] Loss: 0.0573 Acc:97.27% Time:0.3896s
Training:Epoch[003/030] Iteration[008/013] Loss: 0.0739 Acc:97.36% Time:0.3734s
Training:Epoch[003/030] Iteration[010/013] Loss: 0.0497 Acc:97.58% Time:0.3737s
Training:Epoch[003/030] Iteration[012/013] Loss: 0.0510 Acc:97.53% Time:0.3721s
Test:	 Epoch[003/030] Iteration[004/004] Acc:95.07%

The learning rate for epoch 3 is [0.000725, 0.001069, 0.001046, 0.001029, 0.00098, 0.000936, 0.000945, 0.000887, 0.000863, 0.01]
Training:Epoch[004/030] Iteration[002/013] Loss: 0.0628 Acc:98.44% Time:0.3953s
Training:Epoch[004/030] Iteration[004/013] Loss: 0.0411 Acc:98.44% Time:0.3659s
Training:Epoch[004/030] Iteration[006/013] Loss: 0.0758 Acc:97.92% Time:0.3750s
Training:Epoch[004/030] Iteration[008/013] Loss: 0.0343 Acc:98.24% Time:0.3831s
Training:Epoch[004/030] Iteration[010/013] Loss: 0.0765 Acc:97.97% Time:0.3813s
Training:Epoch[004/030] Iteration[012/013] Loss: 0.0316 Acc:98.05% Time:0.3770s
Test:	 Epoch[004/030] Iteration[004/004] Acc:93.63%

The learning rate for epoch 4 is [0.000662, 0.001054, 0.001031, 0.000983, 0.000955, 0.000924, 0.00095, 0.000889, 0.000869, 0.01]
Training:Epoch[005/030] Iteration[002/013] Loss: 0.0622 Acc:96.88% Time:0.3859s
Training:Epoch[005/030] Iteration[004/013] Loss: 0.0095 Acc:98.24% Time:0.3753s
Training:Epoch[005/030] Iteration[006/013] Loss: 0.0191 Acc:98.57% Time:0.3794s
Training:Epoch[005/030] Iteration[008/013] Loss: 0.0399 Acc:98.34% Time:0.3861s
Training:Epoch[005/030] Iteration[010/013] Loss: 0.1128 Acc:97.81% Time:0.3852s
Training:Epoch[005/030] Iteration[012/013] Loss: 0.1076 Acc:97.92% Time:0.3851s
Test:	 Epoch[005/030] Iteration[004/004] Acc:92.61%

The learning rate for epoch 5 is [0.00056, 0.000973, 0.001005, 0.000952, 0.000939, 0.000918, 0.000949, 0.000884, 0.000861, 0.01]
Training:Epoch[006/030] Iteration[002/013] Loss: 0.0539 Acc:98.83% Time:0.3623s
Training:Epoch[006/030] Iteration[004/013] Loss: 0.0187 Acc:98.83% Time:0.3854s
Training:Epoch[006/030] Iteration[006/013] Loss: 0.0586 Acc:98.70% Time:0.3844s
Training:Epoch[006/030] Iteration[008/013] Loss: 0.0509 Acc:98.54% Time:0.4646s
Training:Epoch[006/030] Iteration[010/013] Loss: 0.0503 Acc:98.36% Time:0.3685s
Training:Epoch[006/030] Iteration[012/013] Loss: 0.0667 Acc:98.31% Time:0.3745s
Test:	 Epoch[006/030] Iteration[004/004] Acc:89.32%

The learning rate for epoch 6 is [0.000358, 0.000965, 0.000987, 0.000912, 0.000899, 0.000877, 0.000933, 0.000867, 0.000854, 0.009077]
Training:Epoch[007/030] Iteration[002/013] Loss: 0.0315 Acc:98.05% Time:0.3655s
Training:Epoch[007/030] Iteration[004/013] Loss: 0.0321 Acc:98.44% Time:0.3682s
Training:Epoch[007/030] Iteration[006/013] Loss: 0.0592 Acc:98.31% Time:0.3742s
Training:Epoch[007/030] Iteration[008/013] Loss: 0.0199 Acc:98.54% Time:0.3866s
Training:Epoch[007/030] Iteration[010/013] Loss: 0.0389 Acc:98.44% Time:0.3869s
Training:Epoch[007/030] Iteration[012/013] Loss: 0.0141 Acc:98.63% Time:0.3714s
Test:	 Epoch[007/030] Iteration[004/004] Acc:90.97%

The learning rate for epoch 7 is [0.000366, 0.000934, 0.000971, 0.00089, 0.000878, 0.000865, 0.000929, 0.000869, 0.000857, 0.00965]
Training:Epoch[008/030] Iteration[002/013] Loss: 0.0522 Acc:99.22% Time:0.3829s
Training:Epoch[008/030] Iteration[004/013] Loss: 0.0213 Acc:99.22% Time:0.3847s
Training:Epoch[008/030] Iteration[006/013] Loss: 0.0243 Acc:98.83% Time:0.3858s
Training:Epoch[008/030] Iteration[008/013] Loss: 0.0127 Acc:98.93% Time:0.3958s
Training:Epoch[008/030] Iteration[010/013] Loss: 0.0142 Acc:99.06% Time:0.3956s
Training:Epoch[008/030] Iteration[012/013] Loss: 0.0338 Acc:99.09% Time:0.3736s
Test:	 Epoch[008/030] Iteration[004/004] Acc:94.66%

The learning rate for epoch 8 is [0.000398, 0.000928, 0.000965, 0.000883, 0.000873, 0.000853, 0.000924, 0.000854, 0.000853, 0.009097]
Training:Epoch[009/030] Iteration[002/013] Loss: 0.0558 Acc:97.66% Time:0.3937s
Training:Epoch[009/030] Iteration[004/013] Loss: 0.0146 Acc:98.63% Time:0.3727s
Training:Epoch[009/030] Iteration[006/013] Loss: 0.0138 Acc:98.83% Time:0.3877s
Training:Epoch[009/030] Iteration[008/013] Loss: 0.0627 Acc:98.73% Time:0.3601s
Training:Epoch[009/030] Iteration[010/013] Loss: 0.0374 Acc:98.67% Time:0.3846s
Training:Epoch[009/030] Iteration[012/013] Loss: 0.0330 Acc:98.63% Time:0.3894s
Test:	 Epoch[009/030] Iteration[004/004] Acc:99.18%

The learning rate for epoch 9 is [0.000495, 0.000932, 0.000978, 0.0009, 0.00087, 0.000879, 0.000938, 0.000871, 0.000862, 0.008699]
Training:Epoch[010/030] Iteration[002/013] Loss: 0.0590 Acc:98.44% Time:0.3807s
Training:Epoch[010/030] Iteration[004/013] Loss: 0.0452 Acc:98.83% Time:0.3924s
Training:Epoch[010/030] Iteration[006/013] Loss: 0.0209 Acc:98.70% Time:0.3835s
Training:Epoch[010/030] Iteration[008/013] Loss: 0.0492 Acc:98.63% Time:0.3710s
Training:Epoch[010/030] Iteration[010/013] Loss: 0.0346 Acc:98.52% Time:0.4505s
Training:Epoch[010/030] Iteration[012/013] Loss: 0.0325 Acc:98.44% Time:0.3922s
Test:	 Epoch[010/030] Iteration[004/004] Acc:92.61%

The learning rate for epoch 10 is [0.000454, 0.0009, 0.000964, 0.000896, 0.000868, 0.000877, 0.000935, 0.000869, 0.000859, 0.008242]
Training:Epoch[011/030] Iteration[002/013] Loss: 0.0334 Acc:98.05% Time:0.3797s
Training:Epoch[011/030] Iteration[004/013] Loss: 0.0503 Acc:98.24% Time:0.3857s
Training:Epoch[011/030] Iteration[006/013] Loss: 0.0346 Acc:98.05% Time:0.3699s
Training:Epoch[011/030] Iteration[008/013] Loss: 0.0183 Acc:98.54% Time:0.3843s
Training:Epoch[011/030] Iteration[010/013] Loss: 0.0260 Acc:98.59% Time:0.3861s
Training:Epoch[011/030] Iteration[012/013] Loss: 0.0071 Acc:98.76% Time:0.3379s
Test:	 Epoch[011/030] Iteration[004/004] Acc:97.13%

The learning rate for epoch 11 is [0.000423, 0.000867, 0.00096, 0.000885, 0.000866, 0.00087, 0.000933, 0.000862, 0.000858, 0.008764]
Training:Epoch[012/030] Iteration[002/013] Loss: 0.0439 Acc:98.83% Time:0.3868s
Training:Epoch[012/030] Iteration[004/013] Loss: 0.0058 Acc:99.22% Time:0.3824s
Training:Epoch[012/030] Iteration[006/013] Loss: 0.0176 Acc:99.22% Time:0.3825s
Training:Epoch[012/030] Iteration[008/013] Loss: 0.0214 Acc:99.12% Time:0.3866s
Training:Epoch[012/030] Iteration[010/013] Loss: 0.0053 Acc:99.30% Time:0.3855s
Training:Epoch[012/030] Iteration[012/013] Loss: 0.0167 Acc:99.35% Time:0.3582s
Test:	 Epoch[012/030] Iteration[004/004] Acc:97.54%

The learning rate for epoch 12 is [0.000423, 0.000877, 0.000961, 0.00089, 0.000865, 0.000871, 0.000934, 0.000862, 0.000858, 0.00837]
Training:Epoch[013/030] Iteration[002/013] Loss: 0.0391 Acc:98.44% Time:0.4046s
Training:Epoch[013/030] Iteration[004/013] Loss: 0.0165 Acc:98.63% Time:0.3728s
Training:Epoch[013/030] Iteration[006/013] Loss: 0.0161 Acc:98.70% Time:0.3487s
Training:Epoch[013/030] Iteration[008/013] Loss: 0.0148 Acc:98.93% Time:0.3671s
Training:Epoch[013/030] Iteration[010/013] Loss: 0.0243 Acc:98.83% Time:0.3655s
Training:Epoch[013/030] Iteration[012/013] Loss: 0.0486 Acc:98.70% Time:0.3843s
Test:	 Epoch[013/030] Iteration[004/004] Acc:97.74%

The learning rate for epoch 13 is [0.000491, 0.000899, 0.000973, 0.000902, 0.000859, 0.000875, 0.000939, 0.00087, 0.000859, 0.008465]
Training:Epoch[014/030] Iteration[002/013] Loss: 0.0304 Acc:98.05% Time:0.3406s
Training:Epoch[014/030] Iteration[004/013] Loss: 0.0309 Acc:98.24% Time:0.3909s
Training:Epoch[014/030] Iteration[006/013] Loss: 0.0117 Acc:98.44% Time:0.3651s
Training:Epoch[014/030] Iteration[008/013] Loss: 0.0176 Acc:98.63% Time:0.3822s
Training:Epoch[014/030] Iteration[010/013] Loss: 0.0277 Acc:98.75% Time:0.3690s
Training:Epoch[014/030] Iteration[012/013] Loss: 0.0302 Acc:98.83% Time:0.3854s
Test:	 Epoch[014/030] Iteration[004/004] Acc:90.35%

The learning rate for epoch 14 is [0.000536, 0.00095, 0.001012, 0.000988, 0.000907, 0.000914, 0.000962, 0.000882, 0.00086, 0.008059]
Training:Epoch[015/030] Iteration[002/013] Loss: 0.0120 Acc:99.61% Time:0.3888s
Training:Epoch[015/030] Iteration[004/013] Loss: 0.0249 Acc:99.22% Time:0.3862s
Training:Epoch[015/030] Iteration[006/013] Loss: 0.0282 Acc:98.96% Time:0.3711s
Training:Epoch[015/030] Iteration[008/013] Loss: 0.0372 Acc:98.73% Time:0.3866s
Training:Epoch[015/030] Iteration[010/013] Loss: 0.0354 Acc:98.75% Time:0.4013s
Training:Epoch[015/030] Iteration[012/013] Loss: 0.0238 Acc:98.70% Time:0.3793s
Test:	 Epoch[015/030] Iteration[004/004] Acc:92.81%

The learning rate for epoch 15 is [0.000537, 0.000953, 0.001009, 0.000976, 0.000904, 0.000907, 0.000962, 0.000881, 0.000861, 0.008379]
Training:Epoch[016/030] Iteration[002/013] Loss: 0.0090 Acc:99.61% Time:0.3858s
Training:Epoch[016/030] Iteration[004/013] Loss: 0.0523 Acc:99.22% Time:0.4326s
Training:Epoch[016/030] Iteration[006/013] Loss: 0.0260 Acc:99.09% Time:0.3876s
Training:Epoch[016/030] Iteration[008/013] Loss: 0.0491 Acc:98.83% Time:0.3665s
Training:Epoch[016/030] Iteration[010/013] Loss: 0.0166 Acc:98.91% Time:0.3843s
Training:Epoch[016/030] Iteration[012/013] Loss: 0.0253 Acc:98.89% Time:0.3884s
Test:	 Epoch[016/030] Iteration[004/004] Acc:87.06%

The learning rate for epoch 16 is [0.000655, 0.001027, 0.001016, 0.000981, 0.000904, 0.000903, 0.000956, 0.00088, 0.000862, 0.008101]
Training:Epoch[017/030] Iteration[002/013] Loss: 0.0121 Acc:99.61% Time:0.3826s
Training:Epoch[017/030] Iteration[004/013] Loss: 0.0322 Acc:99.22% Time:0.3971s
Training:Epoch[017/030] Iteration[006/013] Loss: 0.0253 Acc:98.96% Time:0.3854s
Training:Epoch[017/030] Iteration[008/013] Loss: 0.0272 Acc:99.02% Time:0.3618s
Training:Epoch[017/030] Iteration[010/013] Loss: 0.0224 Acc:98.91% Time:0.3870s
Training:Epoch[017/030] Iteration[012/013] Loss: 0.0117 Acc:99.09% Time:0.3803s
Test:	 Epoch[017/030] Iteration[004/004] Acc:98.56%

The learning rate for epoch 17 is [0.000599, 0.001019, 0.001013, 0.00098, 0.000909, 0.00091, 0.000957, 0.000881, 0.000862, 0.008614]
Training:Epoch[018/030] Iteration[002/013] Loss: 0.0230 Acc:99.22% Time:0.3853s
Training:Epoch[018/030] Iteration[004/013] Loss: 0.0041 Acc:99.61% Time:0.3857s
Training:Epoch[018/030] Iteration[006/013] Loss: 0.0095 Acc:99.61% Time:0.3776s
Training:Epoch[018/030] Iteration[008/013] Loss: 0.0148 Acc:99.41% Time:0.3763s
Training:Epoch[018/030] Iteration[010/013] Loss: 0.0125 Acc:99.45% Time:0.3723s
Training:Epoch[018/030] Iteration[012/013] Loss: 0.0053 Acc:99.54% Time:0.3849s
Test:	 Epoch[018/030] Iteration[004/004] Acc:98.36%

The learning rate for epoch 18 is [0.000598, 0.001022, 0.001012, 0.000979, 0.000908, 0.00091, 0.000957, 0.00088, 0.000862, 0.008561]
Training:Epoch[019/030] Iteration[002/013] Loss: 0.0197 Acc:99.22% Time:0.3904s
Training:Epoch[019/030] Iteration[004/013] Loss: 0.0182 Acc:99.41% Time:0.3855s
Training:Epoch[019/030] Iteration[006/013] Loss: 0.0346 Acc:99.09% Time:0.3889s
Training:Epoch[019/030] Iteration[008/013] Loss: 0.0210 Acc:99.02% Time:0.3803s
Training:Epoch[019/030] Iteration[010/013] Loss: 0.0089 Acc:99.14% Time:0.3871s
Training:Epoch[019/030] Iteration[012/013] Loss: 0.0220 Acc:99.02% Time:0.3833s
Test:	 Epoch[019/030] Iteration[004/004] Acc:88.91%

The learning rate for epoch 19 is [0.00054, 0.001036, 0.001011, 0.000996, 0.000912, 0.000914, 0.000959, 0.000878, 0.000862, 0.008645]
Training:Epoch[020/030] Iteration[002/013] Loss: 0.0079 Acc:99.61% Time:0.3751s
Training:Epoch[020/030] Iteration[004/013] Loss: 0.0146 Acc:99.41% Time:0.4366s
Training:Epoch[020/030] Iteration[006/013] Loss: 0.0378 Acc:98.83% Time:0.3741s
Training:Epoch[020/030] Iteration[008/013] Loss: 0.0045 Acc:99.12% Time:0.3843s
Training:Epoch[020/030] Iteration[010/013] Loss: 0.0193 Acc:99.06% Time:0.3826s
Training:Epoch[020/030] Iteration[012/013] Loss: 0.0094 Acc:99.09% Time:0.3859s
Test:	 Epoch[020/030] Iteration[004/004] Acc:82.75%

The learning rate for epoch 20 is [0.000474, 0.000985, 0.000995, 0.000985, 0.000915, 0.00092, 0.00096, 0.000882, 0.000863, 0.008439]
Training:Epoch[021/030] Iteration[002/013] Loss: 0.0090 Acc:99.61% Time:0.3848s
Training:Epoch[021/030] Iteration[004/013] Loss: 0.0064 Acc:99.61% Time:0.3861s
Training:Epoch[021/030] Iteration[006/013] Loss: 0.0387 Acc:99.22% Time:0.3755s
Training:Epoch[021/030] Iteration[008/013] Loss: 0.0484 Acc:99.12% Time:0.3681s
Training:Epoch[021/030] Iteration[010/013] Loss: 0.0297 Acc:98.98% Time:0.3925s
Training:Epoch[021/030] Iteration[012/013] Loss: 0.0485 Acc:98.83% Time:0.3841s
Test:	 Epoch[021/030] Iteration[004/004] Acc:89.53%

The learning rate for epoch 21 is [0.00037, 0.000927, 0.000936, 0.000926, 0.000885, 0.00091, 0.000955, 0.00088, 0.000861, 0.008655]
Training:Epoch[022/030] Iteration[002/013] Loss: 0.0495 Acc:97.66% Time:0.3871s
Training:Epoch[022/030] Iteration[004/013] Loss: 0.0233 Acc:98.24% Time:0.3917s
Training:Epoch[022/030] Iteration[006/013] Loss: 0.1116 Acc:98.18% Time:0.3835s
Training:Epoch[022/030] Iteration[008/013] Loss: 0.0099 Acc:98.54% Time:0.4039s
Training:Epoch[022/030] Iteration[010/013] Loss: 0.0444 Acc:98.44% Time:0.3869s
Training:Epoch[022/030] Iteration[012/013] Loss: 0.0458 Acc:98.37% Time:0.3833s
Test:	 Epoch[022/030] Iteration[004/004] Acc:95.48%

The learning rate for epoch 22 is [0.000305, 0.000933, 0.000938, 0.000909, 0.00088, 0.00091, 0.000952, 0.000878, 0.000861, 0.007524]
Training:Epoch[023/030] Iteration[002/013] Loss: 0.0172 Acc:99.61% Time:0.3820s
Training:Epoch[023/030] Iteration[004/013] Loss: 0.0197 Acc:99.22% Time:0.3854s
Training:Epoch[023/030] Iteration[006/013] Loss: 0.0187 Acc:99.09% Time:0.3787s
Training:Epoch[023/030] Iteration[008/013] Loss: 0.0065 Acc:99.22% Time:0.3737s
Training:Epoch[023/030] Iteration[010/013] Loss: 0.0199 Acc:99.14% Time:0.3829s
Training:Epoch[023/030] Iteration[012/013] Loss: 0.0292 Acc:98.96% Time:0.3614s
Test:	 Epoch[023/030] Iteration[004/004] Acc:94.87%

The learning rate for epoch 23 is [0.000299, 0.000942, 0.000952, 0.000913, 0.000893, 0.000917, 0.000957, 0.00088, 0.000862, 0.008182]
Training:Epoch[024/030] Iteration[002/013] Loss: 0.0117 Acc:100.00% Time:0.3991s
Training:Epoch[024/030] Iteration[004/013] Loss: 0.0510 Acc:98.63% Time:0.3850s
Training:Epoch[024/030] Iteration[006/013] Loss: 0.0180 Acc:98.83% Time:0.3851s
Training:Epoch[024/030] Iteration[008/013] Loss: 0.0045 Acc:99.02% Time:0.3835s
Training:Epoch[024/030] Iteration[010/013] Loss: 0.0223 Acc:98.98% Time:0.3768s
Training:Epoch[024/030] Iteration[012/013] Loss: 0.0084 Acc:99.09% Time:0.3779s
Test:	 Epoch[024/030] Iteration[004/004] Acc:94.66%

The learning rate for epoch 24 is [0.000312, 0.000994, 0.000969, 0.000935, 0.000903, 0.000927, 0.000961, 0.000882, 0.000864, 0.008171]
Training:Epoch[025/030] Iteration[002/013] Loss: 0.0133 Acc:99.22% Time:0.3771s
Training:Epoch[025/030] Iteration[004/013] Loss: 0.0136 Acc:99.41% Time:0.3858s
Training:Epoch[025/030] Iteration[006/013] Loss: 0.0140 Acc:99.35% Time:0.3824s
Training:Epoch[025/030] Iteration[008/013] Loss: 0.0303 Acc:99.22% Time:0.3838s
Training:Epoch[025/030] Iteration[010/013] Loss: 0.0065 Acc:99.30% Time:0.3825s
Training:Epoch[025/030] Iteration[012/013] Loss: 0.0257 Acc:99.22% Time:0.3874s
Test:	 Epoch[025/030] Iteration[004/004] Acc:91.58%

The learning rate for epoch 25 is [0.000309, 0.000989, 0.000968, 0.000946, 0.000916, 0.000935, 0.000963, 0.000884, 0.000864, 0.008112]
Training:Epoch[026/030] Iteration[002/013] Loss: 0.0769 Acc:98.05% Time:0.3653s
Training:Epoch[026/030] Iteration[004/013] Loss: 0.0407 Acc:97.85% Time:0.3928s
Training:Epoch[026/030] Iteration[006/013] Loss: 0.0572 Acc:98.18% Time:0.3726s
Training:Epoch[026/030] Iteration[008/013] Loss: 0.0180 Acc:98.44% Time:0.3841s
Training:Epoch[026/030] Iteration[010/013] Loss: 0.0154 Acc:98.59% Time:0.3684s
Training:Epoch[026/030] Iteration[012/013] Loss: 0.0305 Acc:98.50% Time:0.3846s
Test:	 Epoch[026/030] Iteration[004/004] Acc:85.01%

The learning rate for epoch 26 is [0.000303, 0.000993, 0.000966, 0.000937, 0.000915, 0.000933, 0.000964, 0.000885, 0.000866, 0.007811]
Training:Epoch[027/030] Iteration[002/013] Loss: 0.0343 Acc:99.22% Time:0.3956s
Training:Epoch[027/030] Iteration[004/013] Loss: 0.0166 Acc:99.22% Time:0.3814s
Training:Epoch[027/030] Iteration[006/013] Loss: 0.0196 Acc:99.22% Time:0.3840s
Training:Epoch[027/030] Iteration[008/013] Loss: 0.0179 Acc:99.32% Time:0.3747s
Training:Epoch[027/030] Iteration[010/013] Loss: 0.0248 Acc:99.22% Time:0.3861s
Training:Epoch[027/030] Iteration[012/013] Loss: 0.0182 Acc:99.09% Time:0.3824s
Test:	 Epoch[027/030] Iteration[004/004] Acc:95.69%

The learning rate for epoch 27 is [0.000268, 0.001013, 0.00097, 0.000943, 0.000917, 0.000936, 0.000967, 0.000888, 0.000868, 0.008252]
Training:Epoch[028/030] Iteration[002/013] Loss: 0.0337 Acc:98.83% Time:0.4094s
Training:Epoch[028/030] Iteration[004/013] Loss: 0.0122 Acc:99.02% Time:0.3678s
Training:Epoch[028/030] Iteration[006/013] Loss: 0.0150 Acc:99.22% Time:0.4464s
Training:Epoch[028/030] Iteration[008/013] Loss: 0.0167 Acc:99.32% Time:0.3941s
Training:Epoch[028/030] Iteration[010/013] Loss: 0.0502 Acc:98.98% Time:0.4133s
Training:Epoch[028/030] Iteration[012/013] Loss: 0.0139 Acc:99.02% Time:0.3771s
Test:	 Epoch[028/030] Iteration[004/004] Acc:94.46%

The learning rate for epoch 28 is [0.000247, 0.000992, 0.000963, 0.000939, 0.000921, 0.000936, 0.000967, 0.000888, 0.000865, 0.007375]
Training:Epoch[029/030] Iteration[002/013] Loss: 0.0268 Acc:98.44% Time:0.3866s
Training:Epoch[029/030] Iteration[004/013] Loss: 0.0056 Acc:99.22% Time:0.3759s
Training:Epoch[029/030] Iteration[006/013] Loss: 0.0509 Acc:98.96% Time:0.3949s
Training:Epoch[029/030] Iteration[008/013] Loss: 0.0180 Acc:98.93% Time:0.3824s
Training:Epoch[029/030] Iteration[010/013] Loss: 0.0096 Acc:99.06% Time:0.3914s
Training:Epoch[029/030] Iteration[012/013] Loss: 0.0110 Acc:99.15% Time:0.3935s
Test:	 Epoch[029/030] Iteration[004/004] Acc:98.15%

The learning rate for epoch 29 is [0.00026, 0.000994, 0.000965, 0.000937, 0.000916, 0.000935, 0.000968, 0.000887, 0.000866, 0.007549]
Training:Epoch[030/030] Iteration[002/013] Loss: 0.0705 Acc:98.83% Time:0.3843s
Training:Epoch[030/030] Iteration[004/013] Loss: 0.0145 Acc:99.02% Time:0.3863s
Training:Epoch[030/030] Iteration[006/013] Loss: 0.0045 Acc:99.35% Time:0.3839s
Training:Epoch[030/030] Iteration[008/013] Loss: 0.0193 Acc:99.22% Time:0.3609s
Training:Epoch[030/030] Iteration[010/013] Loss: 0.0217 Acc:99.22% Time:0.3918s
Training:Epoch[030/030] Iteration[012/013] Loss: 0.0184 Acc:99.28% Time:0.3845s
Test:	 Epoch[030/030] Iteration[004/004] Acc:97.95%

The learning rate for epoch 30 is [0.000244, 0.001012, 0.000971, 0.000948, 0.00092, 0.000942, 0.000968, 0.000889, 0.000868, 0.007602]

Training finish, the time consumption of 30 epochs is 231s

The max testing accuracy is: 99.18%, reached at epoch 9.


====================The training of fold 3 start.====================

The self-supervised trained parameters are loaded.


Training start!

Training:Epoch[001/030] Iteration[002/014] Loss: 1.3243 Acc:43.36% Time:0.3851s
Training:Epoch[001/030] Iteration[004/014] Loss: 0.3369 Acc:65.04% Time:0.3728s
Training:Epoch[001/030] Iteration[006/014] Loss: 0.1121 Acc:75.52% Time:0.3746s
Training:Epoch[001/030] Iteration[008/014] Loss: 0.1831 Acc:79.98% Time:0.3923s
Training:Epoch[001/030] Iteration[010/014] Loss: 0.3658 Acc:82.19% Time:0.3846s
Training:Epoch[001/030] Iteration[012/014] Loss: 0.3064 Acc:84.38% Time:0.3846s
Training:Epoch[001/030] Iteration[014/014] Loss: 0.1401 Acc:85.65% Time:0.3931s
Test:	 Epoch[001/030] Iteration[003/003] Acc:69.44%

The learning rate for epoch 1 is [0.001071, 0.000969, 0.000968, 0.000875, 0.000857, 0.000805, 0.000845, 0.000896, 0.000882, 0.01]
Training:Epoch[002/030] Iteration[002/014] Loss: 0.1155 Acc:96.09% Time:0.3782s
Training:Epoch[002/030] Iteration[004/014] Loss: 0.0601 Acc:97.07% Time:0.3859s
Training:Epoch[002/030] Iteration[006/014] Loss: 0.1618 Acc:96.61% Time:0.3647s
Training:Epoch[002/030] Iteration[008/014] Loss: 0.0942 Acc:96.39% Time:0.3842s
Training:Epoch[002/030] Iteration[010/014] Loss: 0.1321 Acc:96.33% Time:0.3875s
Training:Epoch[002/030] Iteration[012/014] Loss: 0.1121 Acc:96.35% Time:0.3872s
Training:Epoch[002/030] Iteration[014/014] Loss: 0.1186 Acc:96.01% Time:0.3975s
Test:	 Epoch[002/030] Iteration[003/003] Acc:87.22%

The learning rate for epoch 2 is [0.001217, 0.000908, 0.000924, 0.000831, 0.000819, 0.000775, 0.000825, 0.000869, 0.000867, 0.01]
Training:Epoch[003/030] Iteration[002/014] Loss: 0.0267 Acc:99.22% Time:0.4071s
Training:Epoch[003/030] Iteration[004/014] Loss: 0.0945 Acc:98.83% Time:0.3707s
Training:Epoch[003/030] Iteration[006/014] Loss: 0.0736 Acc:97.92% Time:0.3824s
Training:Epoch[003/030] Iteration[008/014] Loss: 0.1003 Acc:97.36% Time:0.3512s
Training:Epoch[003/030] Iteration[010/014] Loss: 0.0339 Acc:97.58% Time:0.3728s
Training:Epoch[003/030] Iteration[012/014] Loss: 0.0536 Acc:97.72% Time:0.3893s
Training:Epoch[003/030] Iteration[014/014] Loss: 0.0598 Acc:97.67% Time:0.3770s
Test:	 Epoch[003/030] Iteration[003/003] Acc:79.72%

The learning rate for epoch 3 is [0.001248, 0.000905, 0.000915, 0.000836, 0.000842, 0.000795, 0.000844, 0.000886, 0.000869, 0.01]
Training:Epoch[004/030] Iteration[002/014] Loss: 0.0509 Acc:97.66% Time:0.3867s
Training:Epoch[004/030] Iteration[004/014] Loss: 0.0379 Acc:98.05% Time:0.3820s
Training:Epoch[004/030] Iteration[006/014] Loss: 0.0299 Acc:98.31% Time:0.3686s
Training:Epoch[004/030] Iteration[008/014] Loss: 0.0485 Acc:98.24% Time:0.3813s
Training:Epoch[004/030] Iteration[010/014] Loss: 0.0319 Acc:98.28% Time:0.3831s
Training:Epoch[004/030] Iteration[012/014] Loss: 0.0480 Acc:98.37% Time:0.3765s
Training:Epoch[004/030] Iteration[014/014] Loss: 0.0160 Acc:98.46% Time:0.3924s
Test:	 Epoch[004/030] Iteration[003/003] Acc:76.94%

The learning rate for epoch 4 is [0.001283, 0.000871, 0.000904, 0.000811, 0.000823, 0.000778, 0.000838, 0.00088, 0.000867, 0.01]
Training:Epoch[005/030] Iteration[002/014] Loss: 0.0400 Acc:98.83% Time:0.3847s
Training:Epoch[005/030] Iteration[004/014] Loss: 0.0439 Acc:98.24% Time:0.3815s
Training:Epoch[005/030] Iteration[006/014] Loss: 0.0544 Acc:98.05% Time:0.3856s
Training:Epoch[005/030] Iteration[008/014] Loss: 0.0272 Acc:98.24% Time:0.3859s
Training:Epoch[005/030] Iteration[010/014] Loss: 0.0403 Acc:98.36% Time:0.3831s
Training:Epoch[005/030] Iteration[012/014] Loss: 0.0425 Acc:98.44% Time:0.3782s
Training:Epoch[005/030] Iteration[014/014] Loss: 0.0455 Acc:98.52% Time:0.3794s
Test:	 Epoch[005/030] Iteration[003/003] Acc:89.17%

The learning rate for epoch 5 is [0.001321, 0.000878, 0.000904, 0.000815, 0.000835, 0.000784, 0.000838, 0.000877, 0.000867, 0.01]
Training:Epoch[006/030] Iteration[002/014] Loss: 0.0201 Acc:98.83% Time:0.3845s
Training:Epoch[006/030] Iteration[004/014] Loss: 0.0045 Acc:99.41% Time:0.3846s
Training:Epoch[006/030] Iteration[006/014] Loss: 0.0198 Acc:99.35% Time:0.3731s
Training:Epoch[006/030] Iteration[008/014] Loss: 0.0462 Acc:99.12% Time:0.3731s
Training:Epoch[006/030] Iteration[010/014] Loss: 0.0273 Acc:99.22% Time:0.3845s
Training:Epoch[006/030] Iteration[012/014] Loss: 0.0228 Acc:99.22% Time:0.3752s
Training:Epoch[006/030] Iteration[014/014] Loss: 0.0141 Acc:99.20% Time:0.3821s
Test:	 Epoch[006/030] Iteration[003/003] Acc:89.17%

The learning rate for epoch 6 is [0.001337, 0.000873, 0.000897, 0.000804, 0.000828, 0.000782, 0.000837, 0.000876, 0.000867, 0.009913]
Training:Epoch[007/030] Iteration[002/014] Loss: 0.0208 Acc:99.22% Time:0.4348s
Training:Epoch[007/030] Iteration[004/014] Loss: 0.0236 Acc:99.02% Time:0.3704s
Training:Epoch[007/030] Iteration[006/014] Loss: 0.0114 Acc:99.09% Time:0.3800s
Training:Epoch[007/030] Iteration[008/014] Loss: 0.0017 Acc:99.32% Time:0.3695s
Training:Epoch[007/030] Iteration[010/014] Loss: 0.0088 Acc:99.30% Time:0.4093s
Training:Epoch[007/030] Iteration[012/014] Loss: 0.0029 Acc:99.41% Time:0.3814s
Training:Epoch[007/030] Iteration[014/014] Loss: 0.0123 Acc:99.43% Time:0.4064s
Test:	 Epoch[007/030] Iteration[003/003] Acc:89.44%

The learning rate for epoch 7 is [0.001536, 0.000939, 0.000908, 0.000825, 0.00084, 0.000787, 0.00084, 0.000878, 0.000869, 0.01]
Training:Epoch[008/030] Iteration[002/014] Loss: 0.0063 Acc:99.61% Time:0.3733s
Training:Epoch[008/030] Iteration[004/014] Loss: 0.0087 Acc:99.61% Time:0.3601s
Training:Epoch[008/030] Iteration[006/014] Loss: 0.0217 Acc:99.35% Time:0.3557s
Training:Epoch[008/030] Iteration[008/014] Loss: 0.0064 Acc:99.41% Time:0.3754s
Training:Epoch[008/030] Iteration[010/014] Loss: 0.0051 Acc:99.53% Time:0.3877s
Training:Epoch[008/030] Iteration[012/014] Loss: 0.0907 Acc:99.41% Time:0.3694s
Training:Epoch[008/030] Iteration[014/014] Loss: 0.0031 Acc:99.49% Time:0.4107s
Test:	 Epoch[008/030] Iteration[003/003] Acc:85.28%

The learning rate for epoch 8 is [0.001569, 0.000942, 0.000908, 0.000826, 0.000837, 0.000788, 0.000841, 0.000882, 0.000869, 0.009955]
Training:Epoch[009/030] Iteration[002/014] Loss: 0.0193 Acc:99.61% Time:0.3717s
Training:Epoch[009/030] Iteration[004/014] Loss: 0.0144 Acc:99.61% Time:0.3814s
Training:Epoch[009/030] Iteration[006/014] Loss: 0.0182 Acc:99.35% Time:0.3933s
Training:Epoch[009/030] Iteration[008/014] Loss: 0.0076 Acc:99.41% Time:0.3737s
Training:Epoch[009/030] Iteration[010/014] Loss: 0.0139 Acc:99.45% Time:0.3879s
Training:Epoch[009/030] Iteration[012/014] Loss: 0.0211 Acc:99.35% Time:0.3842s
Training:Epoch[009/030] Iteration[014/014] Loss: 0.0100 Acc:99.37% Time:0.3799s
Test:	 Epoch[009/030] Iteration[003/003] Acc:90.00%

The learning rate for epoch 9 is [0.0015, 0.000969, 0.000911, 0.000832, 0.000839, 0.000792, 0.000841, 0.000883, 0.00087, 0.009659]
Training:Epoch[010/030] Iteration[002/014] Loss: 0.0084 Acc:99.61% Time:0.3637s
Training:Epoch[010/030] Iteration[004/014] Loss: 0.0110 Acc:99.61% Time:0.3873s
Training:Epoch[010/030] Iteration[006/014] Loss: 0.0099 Acc:99.61% Time:0.3839s
Training:Epoch[010/030] Iteration[008/014] Loss: 0.0213 Acc:99.51% Time:0.3892s
Training:Epoch[010/030] Iteration[010/014] Loss: 0.0912 Acc:99.30% Time:0.3665s
Training:Epoch[010/030] Iteration[012/014] Loss: 0.0237 Acc:99.28% Time:0.3833s
Training:Epoch[010/030] Iteration[014/014] Loss: 0.0949 Acc:99.15% Time:0.3960s
Test:	 Epoch[010/030] Iteration[003/003] Acc:83.33%

The learning rate for epoch 10 is [0.001847, 0.00101, 0.000919, 0.000801, 0.000786, 0.000713, 0.000815, 0.000855, 0.000851, 0.008333]
Training:Epoch[011/030] Iteration[002/014] Loss: 0.0499 Acc:98.05% Time:0.3853s
Training:Epoch[011/030] Iteration[004/014] Loss: 0.0775 Acc:97.66% Time:0.3928s
Training:Epoch[011/030] Iteration[006/014] Loss: 0.0622 Acc:97.66% Time:0.4397s
Training:Epoch[011/030] Iteration[008/014] Loss: 0.0488 Acc:97.85% Time:0.3840s
Training:Epoch[011/030] Iteration[010/014] Loss: 0.0379 Acc:97.89% Time:0.4669s
Training:Epoch[011/030] Iteration[012/014] Loss: 0.0215 Acc:98.18% Time:0.3880s
Training:Epoch[011/030] Iteration[014/014] Loss: 0.0247 Acc:98.29% Time:0.3798s
Test:	 Epoch[011/030] Iteration[003/003] Acc:80.00%

The learning rate for epoch 11 is [0.001679, 0.000942, 0.00091, 0.000778, 0.000781, 0.000707, 0.00081, 0.00085, 0.00085, 0.009305]
Training:Epoch[012/030] Iteration[002/014] Loss: 0.0629 Acc:98.44% Time:0.3795s
Training:Epoch[012/030] Iteration[004/014] Loss: 0.0338 Acc:98.44% Time:0.3878s
Training:Epoch[012/030] Iteration[006/014] Loss: 0.0262 Acc:98.57% Time:0.4158s
Training:Epoch[012/030] Iteration[008/014] Loss: 0.0270 Acc:98.73% Time:0.3875s
Training:Epoch[012/030] Iteration[010/014] Loss: 0.0325 Acc:98.59% Time:0.3662s
Training:Epoch[012/030] Iteration[012/014] Loss: 0.0271 Acc:98.76% Time:0.3686s
Training:Epoch[012/030] Iteration[014/014] Loss: 0.0549 Acc:98.52% Time:0.3999s
Test:	 Epoch[012/030] Iteration[003/003] Acc:85.56%

The learning rate for epoch 12 is [0.001616, 0.000924, 0.000909, 0.000772, 0.000776, 0.000705, 0.000814, 0.000853, 0.00085, 0.009233]
Training:Epoch[013/030] Iteration[002/014] Loss: 0.0085 Acc:99.61% Time:0.3784s
Training:Epoch[013/030] Iteration[004/014] Loss: 0.0122 Acc:99.22% Time:0.3794s
Training:Epoch[013/030] Iteration[006/014] Loss: 0.0322 Acc:99.22% Time:0.3646s
Training:Epoch[013/030] Iteration[008/014] Loss: 0.0301 Acc:99.22% Time:0.3684s
Training:Epoch[013/030] Iteration[010/014] Loss: 0.0471 Acc:98.98% Time:0.3843s
Training:Epoch[013/030] Iteration[012/014] Loss: 0.0567 Acc:98.76% Time:0.3851s
Training:Epoch[013/030] Iteration[014/014] Loss: 0.0213 Acc:98.80% Time:0.4007s
Test:	 Epoch[013/030] Iteration[003/003] Acc:88.61%

The learning rate for epoch 13 is [0.001658, 0.000946, 0.000923, 0.00077, 0.000818, 0.000739, 0.000834, 0.000883, 0.000859, 0.008959]
Training:Epoch[014/030] Iteration[002/014] Loss: 0.0339 Acc:98.05% Time:0.3886s
Training:Epoch[014/030] Iteration[004/014] Loss: 0.0215 Acc:98.63% Time:0.3863s
Training:Epoch[014/030] Iteration[006/014] Loss: 0.0611 Acc:98.31% Time:0.3793s
Training:Epoch[014/030] Iteration[008/014] Loss: 0.0560 Acc:98.24% Time:0.3905s
Training:Epoch[014/030] Iteration[010/014] Loss: 0.0184 Acc:98.44% Time:0.3854s
Training:Epoch[014/030] Iteration[012/014] Loss: 0.0787 Acc:98.24% Time:0.3843s
Training:Epoch[014/030] Iteration[014/014] Loss: 0.0509 Acc:98.23% Time:0.4041s
Test:	 Epoch[014/030] Iteration[003/003] Acc:80.56%

The learning rate for epoch 14 is [0.001549, 0.001076, 0.000972, 0.00082, 0.00084, 0.00077, 0.000845, 0.00089, 0.000859, 0.009416]
Training:Epoch[015/030] Iteration[002/014] Loss: 0.0561 Acc:97.66% Time:0.3878s
Training:Epoch[015/030] Iteration[004/014] Loss: 0.0304 Acc:97.85% Time:0.3898s
Training:Epoch[015/030] Iteration[006/014] Loss: 0.0298 Acc:98.31% Time:0.3722s
Training:Epoch[015/030] Iteration[008/014] Loss: 0.0336 Acc:98.44% Time:0.3821s
Training:Epoch[015/030] Iteration[010/014] Loss: 0.0124 Acc:98.67% Time:0.3663s
Training:Epoch[015/030] Iteration[012/014] Loss: 0.0165 Acc:98.76% Time:0.3853s
Training:Epoch[015/030] Iteration[014/014] Loss: 0.0710 Acc:98.46% Time:0.3836s
Test:	 Epoch[015/030] Iteration[003/003] Acc:86.94%

The learning rate for epoch 15 is [0.00151, 0.001127, 0.000992, 0.000809, 0.000841, 0.000767, 0.000844, 0.000885, 0.000861, 0.009036]
Training:Epoch[016/030] Iteration[002/014] Loss: 0.0447 Acc:98.83% Time:0.3516s
Training:Epoch[016/030] Iteration[004/014] Loss: 0.0242 Acc:98.83% Time:0.3705s
Training:Epoch[016/030] Iteration[006/014] Loss: 0.0185 Acc:98.96% Time:0.3759s
Training:Epoch[016/030] Iteration[008/014] Loss: 0.0851 Acc:98.54% Time:0.3586s
Training:Epoch[016/030] Iteration[010/014] Loss: 0.0451 Acc:98.36% Time:0.3822s
Training:Epoch[016/030] Iteration[012/014] Loss: 0.0778 Acc:98.31% Time:0.3668s
Training:Epoch[016/030] Iteration[014/014] Loss: 0.0531 Acc:98.41% Time:0.4323s
Test:	 Epoch[016/030] Iteration[003/003] Acc:91.94%

The learning rate for epoch 16 is [0.001539, 0.001213, 0.001014, 0.000817, 0.000867, 0.000782, 0.000862, 0.0009, 0.000869, 0.00939]
Training:Epoch[017/030] Iteration[002/014] Loss: 0.0666 Acc:97.66% Time:0.3780s
Training:Epoch[017/030] Iteration[004/014] Loss: 0.0314 Acc:98.24% Time:0.3651s
Training:Epoch[017/030] Iteration[006/014] Loss: 0.0312 Acc:98.44% Time:0.3912s
Training:Epoch[017/030] Iteration[008/014] Loss: 0.0715 Acc:97.95% Time:0.3825s
Training:Epoch[017/030] Iteration[010/014] Loss: 0.0156 Acc:98.28% Time:0.3664s
Training:Epoch[017/030] Iteration[012/014] Loss: 0.0465 Acc:98.11% Time:0.3874s
Training:Epoch[017/030] Iteration[014/014] Loss: 0.0372 Acc:98.06% Time:0.4012s
Test:	 Epoch[017/030] Iteration[003/003] Acc:86.67%

The learning rate for epoch 17 is [0.001466, 0.001144, 0.001, 0.000771, 0.000843, 0.000766, 0.000859, 0.000894, 0.00087, 0.008946]
Training:Epoch[018/030] Iteration[002/014] Loss: 0.0204 Acc:99.61% Time:0.3892s
Training:Epoch[018/030] Iteration[004/014] Loss: 0.0143 Acc:99.41% Time:0.3859s
Training:Epoch[018/030] Iteration[006/014] Loss: 0.0846 Acc:98.83% Time:0.3682s
Training:Epoch[018/030] Iteration[008/014] Loss: 0.0141 Acc:98.93% Time:0.3749s
Training:Epoch[018/030] Iteration[010/014] Loss: 0.0526 Acc:98.83% Time:0.3830s
Training:Epoch[018/030] Iteration[012/014] Loss: 0.0290 Acc:98.70% Time:0.3851s
Training:Epoch[018/030] Iteration[014/014] Loss: 0.0161 Acc:98.75% Time:0.3904s
Test:	 Epoch[018/030] Iteration[003/003] Acc:87.22%

The learning rate for epoch 18 is [0.001143, 0.001111, 0.000988, 0.000768, 0.000832, 0.000758, 0.000857, 0.000894, 0.00087, 0.008625]
Training:Epoch[019/030] Iteration[002/014] Loss: 0.0190 Acc:98.83% Time:0.3874s
Training:Epoch[019/030] Iteration[004/014] Loss: 0.0177 Acc:98.83% Time:0.3926s
Training:Epoch[019/030] Iteration[006/014] Loss: 0.0086 Acc:99.09% Time:0.3902s
Training:Epoch[019/030] Iteration[008/014] Loss: 0.0263 Acc:98.93% Time:0.3738s
Training:Epoch[019/030] Iteration[010/014] Loss: 0.0081 Acc:99.06% Time:0.3967s
Training:Epoch[019/030] Iteration[012/014] Loss: 0.0117 Acc:99.15% Time:0.3709s
Training:Epoch[019/030] Iteration[014/014] Loss: 0.0261 Acc:99.09% Time:0.3938s
Test:	 Epoch[019/030] Iteration[003/003] Acc:95.00%

The learning rate for epoch 19 is [0.00114, 0.0011, 0.000987, 0.000765, 0.00083, 0.000755, 0.000857, 0.000893, 0.000871, 0.008769]
Training:Epoch[020/030] Iteration[002/014] Loss: 0.0504 Acc:98.44% Time:0.3902s
Training:Epoch[020/030] Iteration[004/014] Loss: 0.0081 Acc:99.22% Time:0.3850s
Training:Epoch[020/030] Iteration[006/014] Loss: 0.0083 Acc:99.22% Time:0.4429s
Training:Epoch[020/030] Iteration[008/014] Loss: 0.0194 Acc:99.22% Time:0.3925s
Training:Epoch[020/030] Iteration[010/014] Loss: 0.0275 Acc:99.14% Time:0.4165s
Training:Epoch[020/030] Iteration[012/014] Loss: 0.0051 Acc:99.22% Time:0.3877s
Training:Epoch[020/030] Iteration[014/014] Loss: 0.0361 Acc:99.09% Time:0.3795s
Test:	 Epoch[020/030] Iteration[003/003] Acc:86.94%

The learning rate for epoch 20 is [0.001194, 0.001122, 0.000991, 0.000781, 0.000845, 0.00077, 0.000866, 0.000903, 0.000873, 0.008913]
Training:Epoch[021/030] Iteration[002/014] Loss: 0.0025 Acc:100.00% Time:0.3626s
Training:Epoch[021/030] Iteration[004/014] Loss: 0.0352 Acc:99.41% Time:0.3643s
Training:Epoch[021/030] Iteration[006/014] Loss: 0.0143 Acc:99.48% Time:0.3681s
Training:Epoch[021/030] Iteration[008/014] Loss: 0.0009 Acc:99.61% Time:0.3629s
Training:Epoch[021/030] Iteration[010/014] Loss: 0.0107 Acc:99.45% Time:0.3327s
Training:Epoch[021/030] Iteration[012/014] Loss: 0.0336 Acc:99.09% Time:0.3880s
Training:Epoch[021/030] Iteration[014/014] Loss: 0.0296 Acc:98.97% Time:0.3708s
Test:	 Epoch[021/030] Iteration[003/003] Acc:88.33%

The learning rate for epoch 21 is [0.001248, 0.00113, 0.000992, 0.000781, 0.000846, 0.000766, 0.000863, 0.000899, 0.000873, 0.008752]
Training:Epoch[022/030] Iteration[002/014] Loss: 0.0111 Acc:99.61% Time:0.3691s
Training:Epoch[022/030] Iteration[004/014] Loss: 0.0147 Acc:99.22% Time:0.3838s
Training:Epoch[022/030] Iteration[006/014] Loss: 0.0262 Acc:98.70% Time:0.3854s
Training:Epoch[022/030] Iteration[008/014] Loss: 0.0142 Acc:98.83% Time:0.3831s
Training:Epoch[022/030] Iteration[010/014] Loss: 0.0040 Acc:99.06% Time:0.3849s
Training:Epoch[022/030] Iteration[012/014] Loss: 0.0155 Acc:99.09% Time:0.3843s
Training:Epoch[022/030] Iteration[014/014] Loss: 0.0143 Acc:99.03% Time:0.4696s
Test:	 Epoch[022/030] Iteration[003/003] Acc:92.50%

The learning rate for epoch 22 is [0.001288, 0.001132, 0.000995, 0.000784, 0.00085, 0.000768, 0.000863, 0.0009, 0.000874, 0.00914]
Training:Epoch[023/030] Iteration[002/014] Loss: 0.0192 Acc:99.61% Time:0.3656s
Training:Epoch[023/030] Iteration[004/014] Loss: 0.0107 Acc:99.22% Time:0.3673s
Training:Epoch[023/030] Iteration[006/014] Loss: 0.0085 Acc:99.35% Time:0.3641s
Training:Epoch[023/030] Iteration[008/014] Loss: 0.0043 Acc:99.41% Time:0.3885s
Training:Epoch[023/030] Iteration[010/014] Loss: 0.0088 Acc:99.38% Time:0.3966s
Training:Epoch[023/030] Iteration[012/014] Loss: 0.0082 Acc:99.41% Time:0.3936s
Training:Epoch[023/030] Iteration[014/014] Loss: 0.0057 Acc:99.43% Time:0.4000s
Test:	 Epoch[023/030] Iteration[003/003] Acc:93.06%

The learning rate for epoch 23 is [0.001294, 0.001133, 0.000995, 0.000785, 0.00085, 0.000768, 0.000863, 0.0009, 0.000874, 0.009139]
Training:Epoch[024/030] Iteration[002/014] Loss: 0.0156 Acc:98.44% Time:0.3381s
Training:Epoch[024/030] Iteration[004/014] Loss: 0.0144 Acc:98.44% Time:0.3859s
Training:Epoch[024/030] Iteration[006/014] Loss: 0.0073 Acc:98.96% Time:0.3850s
Training:Epoch[024/030] Iteration[008/014] Loss: 0.0187 Acc:98.73% Time:0.3834s
Training:Epoch[024/030] Iteration[010/014] Loss: 0.0156 Acc:98.91% Time:0.3913s
Training:Epoch[024/030] Iteration[012/014] Loss: 0.0330 Acc:98.96% Time:0.3827s
Training:Epoch[024/030] Iteration[014/014] Loss: 0.0136 Acc:98.97% Time:0.3602s
Test:	 Epoch[024/030] Iteration[003/003] Acc:88.06%

The learning rate for epoch 24 is [0.001306, 0.001112, 0.000984, 0.000771, 0.000841, 0.000764, 0.000865, 0.000901, 0.000875, 0.009287]
Training:Epoch[025/030] Iteration[002/014] Loss: 0.0224 Acc:97.66% Time:0.3578s
Training:Epoch[025/030] Iteration[004/014] Loss: 0.0074 Acc:98.44% Time:0.3694s
Training:Epoch[025/030] Iteration[006/014] Loss: 0.0116 Acc:98.70% Time:0.3919s
Training:Epoch[025/030] Iteration[008/014] Loss: 0.0067 Acc:98.93% Time:0.3722s
Training:Epoch[025/030] Iteration[010/014] Loss: 0.0037 Acc:99.06% Time:0.3647s
Training:Epoch[025/030] Iteration[012/014] Loss: 0.0044 Acc:99.22% Time:0.3858s
Training:Epoch[025/030] Iteration[014/014] Loss: 0.0175 Acc:99.20% Time:0.3740s
Test:	 Epoch[025/030] Iteration[003/003] Acc:87.22%

The learning rate for epoch 25 is [0.001228, 0.001113, 0.000983, 0.00077, 0.000839, 0.000762, 0.000865, 0.000903, 0.000877, 0.009303]
Training:Epoch[026/030] Iteration[002/014] Loss: 0.0080 Acc:100.00% Time:0.3766s
Training:Epoch[026/030] Iteration[004/014] Loss: 0.0389 Acc:99.22% Time:0.3824s
Training:Epoch[026/030] Iteration[006/014] Loss: 0.0140 Acc:99.35% Time:0.3676s
Training:Epoch[026/030] Iteration[008/014] Loss: 0.0175 Acc:99.22% Time:0.3736s
Training:Epoch[026/030] Iteration[010/014] Loss: 0.0163 Acc:99.14% Time:0.3833s
Training:Epoch[026/030] Iteration[012/014] Loss: 0.0790 Acc:98.83% Time:0.3856s
Training:Epoch[026/030] Iteration[014/014] Loss: 0.0076 Acc:98.97% Time:0.3948s
Test:	 Epoch[026/030] Iteration[003/003] Acc:92.78%

The learning rate for epoch 26 is [0.001224, 0.001115, 0.000987, 0.000777, 0.000846, 0.000764, 0.000865, 0.000903, 0.000875, 0.009524]
Training:Epoch[027/030] Iteration[002/014] Loss: 0.0228 Acc:98.44% Time:0.3865s
Training:Epoch[027/030] Iteration[004/014] Loss: 0.0120 Acc:98.83% Time:0.3773s
Training:Epoch[027/030] Iteration[006/014] Loss: 0.0306 Acc:98.96% Time:0.3919s
Training:Epoch[027/030] Iteration[008/014] Loss: 0.0056 Acc:99.22% Time:0.3909s
Training:Epoch[027/030] Iteration[010/014] Loss: 0.0113 Acc:99.30% Time:0.4121s
Training:Epoch[027/030] Iteration[012/014] Loss: 0.0175 Acc:99.28% Time:0.3818s
Training:Epoch[027/030] Iteration[014/014] Loss: 0.0158 Acc:99.32% Time:0.3909s
Test:	 Epoch[027/030] Iteration[003/003] Acc:88.06%

The learning rate for epoch 27 is [0.001227, 0.001114, 0.000982, 0.000768, 0.000837, 0.000757, 0.000863, 0.000901, 0.000875, 0.008787]
Training:Epoch[028/030] Iteration[002/014] Loss: 0.0106 Acc:99.22% Time:0.4005s
Training:Epoch[028/030] Iteration[004/014] Loss: 0.0355 Acc:99.02% Time:0.3716s
Training:Epoch[028/030] Iteration[006/014] Loss: 0.0177 Acc:98.96% Time:0.3747s
Training:Epoch[028/030] Iteration[008/014] Loss: 0.0313 Acc:98.83% Time:0.3826s
Training:Epoch[028/030] Iteration[010/014] Loss: 0.0198 Acc:98.83% Time:0.3878s
Training:Epoch[028/030] Iteration[012/014] Loss: 0.0169 Acc:98.83% Time:0.3818s
Training:Epoch[028/030] Iteration[014/014] Loss: 0.0109 Acc:98.97% Time:0.3899s
Test:	 Epoch[028/030] Iteration[003/003] Acc:88.06%

The learning rate for epoch 28 is [0.001223, 0.001126, 0.000987, 0.000773, 0.000839, 0.000759, 0.000863, 0.000901, 0.000876, 0.009053]
Training:Epoch[029/030] Iteration[002/014] Loss: 0.0045 Acc:99.61% Time:0.3865s
Training:Epoch[029/030] Iteration[004/014] Loss: 0.0451 Acc:98.83% Time:0.3809s
Training:Epoch[029/030] Iteration[006/014] Loss: 0.0190 Acc:98.70% Time:0.3694s
Training:Epoch[029/030] Iteration[008/014] Loss: 0.0113 Acc:99.02% Time:0.3857s
Training:Epoch[029/030] Iteration[010/014] Loss: 0.0094 Acc:99.14% Time:0.3740s
Training:Epoch[029/030] Iteration[012/014] Loss: 0.0035 Acc:99.28% Time:0.3911s
Training:Epoch[029/030] Iteration[014/014] Loss: 0.0269 Acc:99.26% Time:0.3913s
Test:	 Epoch[029/030] Iteration[003/003] Acc:85.83%

The learning rate for epoch 29 is [0.00122, 0.001112, 0.000976, 0.000754, 0.000827, 0.000753, 0.000861, 0.000899, 0.000876, 0.008905]
Training:Epoch[030/030] Iteration[002/014] Loss: 0.0069 Acc:100.00% Time:0.3869s
Training:Epoch[030/030] Iteration[004/014] Loss: 0.0094 Acc:99.61% Time:0.3753s
Training:Epoch[030/030] Iteration[006/014] Loss: 0.0117 Acc:99.48% Time:0.3728s
Training:Epoch[030/030] Iteration[008/014] Loss: 0.0149 Acc:99.32% Time:0.3913s
Training:Epoch[030/030] Iteration[010/014] Loss: 0.0285 Acc:99.14% Time:0.3850s
Training:Epoch[030/030] Iteration[012/014] Loss: 0.0086 Acc:99.22% Time:0.3689s
Training:Epoch[030/030] Iteration[014/014] Loss: 0.0215 Acc:99.20% Time:0.3768s
Test:	 Epoch[030/030] Iteration[003/003] Acc:89.17%

The learning rate for epoch 30 is [0.001256, 0.00113, 0.000979, 0.000755, 0.000822, 0.00075, 0.00086, 0.000898, 0.000875, 0.009035]

Training finish, the time consumption of 30 epochs is 243s

The max testing accuracy is: 95.00%, reached at epoch 19.


====================The training of fold 4 start.====================

The self-supervised trained parameters are loaded.


Training start!

Training:Epoch[001/030] Iteration[002/014] Loss: 0.8731 Acc:57.42% Time:0.3605s
Training:Epoch[001/030] Iteration[004/014] Loss: 0.3593 Acc:71.68% Time:0.4009s
Training:Epoch[001/030] Iteration[006/014] Loss: 0.2442 Acc:77.99% Time:0.3833s
Training:Epoch[001/030] Iteration[008/014] Loss: 0.1001 Acc:82.32% Time:0.3812s
Training:Epoch[001/030] Iteration[010/014] Loss: 0.1132 Acc:85.23% Time:0.3887s
Training:Epoch[001/030] Iteration[012/014] Loss: 0.0638 Acc:87.50% Time:0.3830s
Training:Epoch[001/030] Iteration[014/014] Loss: 0.2781 Acc:88.18% Time:0.3908s
Test:	 Epoch[001/030] Iteration[004/004] Acc:77.12%

The learning rate for epoch 1 is [0.000691, 0.000948, 0.00096, 0.000946, 0.00095, 0.00094, 0.000989, 0.000927, 0.000858, 0.01]
Training:Epoch[002/030] Iteration[002/014] Loss: 0.1378 Acc:96.09% Time:0.3812s
Training:Epoch[002/030] Iteration[004/014] Loss: 0.1330 Acc:96.48% Time:0.3791s
Training:Epoch[002/030] Iteration[006/014] Loss: 0.0793 Acc:97.14% Time:0.3847s
Training:Epoch[002/030] Iteration[008/014] Loss: 0.1021 Acc:96.68% Time:0.3852s
Training:Epoch[002/030] Iteration[010/014] Loss: 0.0948 Acc:96.48% Time:0.3668s
Training:Epoch[002/030] Iteration[012/014] Loss: 0.1152 Acc:96.55% Time:0.3873s
Training:Epoch[002/030] Iteration[014/014] Loss: 0.0682 Acc:96.69% Time:0.3781s
Test:	 Epoch[002/030] Iteration[004/004] Acc:85.38%

The learning rate for epoch 2 is [0.000655, 0.000894, 0.000948, 0.000908, 0.0009, 0.000906, 0.000975, 0.000907, 0.000858, 0.01]
Training:Epoch[003/030] Iteration[002/014] Loss: 0.0295 Acc:99.22% Time:0.3672s
Training:Epoch[003/030] Iteration[004/014] Loss: 0.0242 Acc:99.22% Time:0.3890s
Training:Epoch[003/030] Iteration[006/014] Loss: 0.0803 Acc:98.44% Time:0.3690s
Training:Epoch[003/030] Iteration[008/014] Loss: 0.0723 Acc:98.14% Time:0.3872s
Training:Epoch[003/030] Iteration[010/014] Loss: 0.1404 Acc:97.89% Time:0.3629s
Training:Epoch[003/030] Iteration[012/014] Loss: 0.0494 Acc:98.05% Time:0.3745s
Training:Epoch[003/030] Iteration[014/014] Loss: 0.2374 Acc:97.99% Time:0.3630s
Test:	 Epoch[003/030] Iteration[004/004] Acc:91.51%

The learning rate for epoch 3 is [0.00058, 0.000943, 0.00094, 0.000876, 0.000873, 0.000874, 0.00093, 0.000872, 0.000845, 0.01]
Training:Epoch[004/030] Iteration[002/014] Loss: 0.0159 Acc:100.00% Time:0.3850s
Training:Epoch[004/030] Iteration[004/014] Loss: 0.0359 Acc:99.61% Time:0.3869s
Training:Epoch[004/030] Iteration[006/014] Loss: 0.0778 Acc:98.83% Time:0.3837s
Training:Epoch[004/030] Iteration[008/014] Loss: 0.0459 Acc:98.73% Time:0.3585s
Training:Epoch[004/030] Iteration[010/014] Loss: 0.0211 Acc:98.83% Time:0.3487s
Training:Epoch[004/030] Iteration[012/014] Loss: 0.0645 Acc:98.76% Time:0.3861s
Training:Epoch[004/030] Iteration[014/014] Loss: 0.0214 Acc:98.82% Time:0.3720s
Test:	 Epoch[004/030] Iteration[004/004] Acc:83.25%

The learning rate for epoch 4 is [0.00062, 0.000931, 0.000924, 0.000848, 0.000865, 0.000875, 0.000931, 0.00085, 0.000852, 0.01]
Training:Epoch[005/030] Iteration[002/014] Loss: 0.0317 Acc:99.61% Time:0.3882s
Training:Epoch[005/030] Iteration[004/014] Loss: 0.0075 Acc:99.80% Time:0.3668s
Training:Epoch[005/030] Iteration[006/014] Loss: 0.0609 Acc:99.22% Time:0.3831s
Training:Epoch[005/030] Iteration[008/014] Loss: 0.0225 Acc:99.22% Time:0.3869s
Training:Epoch[005/030] Iteration[010/014] Loss: 0.0083 Acc:99.38% Time:0.3863s
Training:Epoch[005/030] Iteration[012/014] Loss: 0.0675 Acc:99.15% Time:0.3875s
Training:Epoch[005/030] Iteration[014/014] Loss: 0.0868 Acc:99.11% Time:0.3874s
Test:	 Epoch[005/030] Iteration[004/004] Acc:84.91%

The learning rate for epoch 5 is [0.000454, 0.000877, 0.000896, 0.000823, 0.000841, 0.00086, 0.000931, 0.000852, 0.000856, 0.01]
Training:Epoch[006/030] Iteration[002/014] Loss: 0.0185 Acc:99.22% Time:0.3821s
Training:Epoch[006/030] Iteration[004/014] Loss: 0.0526 Acc:98.44% Time:0.3641s
Training:Epoch[006/030] Iteration[006/014] Loss: 0.0783 Acc:98.18% Time:0.3768s
Training:Epoch[006/030] Iteration[008/014] Loss: 0.0559 Acc:98.24% Time:0.3645s
Training:Epoch[006/030] Iteration[010/014] Loss: 0.0121 Acc:98.59% Time:0.3876s
Training:Epoch[006/030] Iteration[012/014] Loss: 0.0235 Acc:98.76% Time:0.3770s
Training:Epoch[006/030] Iteration[014/014] Loss: 0.0682 Acc:98.70% Time:0.3706s
Test:	 Epoch[006/030] Iteration[004/004] Acc:92.45%

The learning rate for epoch 6 is [0.000298, 0.000807, 0.000832, 0.000772, 0.000834, 0.000824, 0.000923, 0.00084, 0.000852, 0.008853]
Training:Epoch[007/030] Iteration[002/014] Loss: 0.0078 Acc:99.61% Time:0.4591s
Training:Epoch[007/030] Iteration[004/014] Loss: 0.0263 Acc:99.41% Time:0.3730s
Training:Epoch[007/030] Iteration[006/014] Loss: 0.1422 Acc:98.83% Time:0.3869s
Training:Epoch[007/030] Iteration[008/014] Loss: 0.0562 Acc:98.73% Time:0.3899s
Training:Epoch[007/030] Iteration[010/014] Loss: 0.0292 Acc:98.83% Time:0.3781s
Training:Epoch[007/030] Iteration[012/014] Loss: 0.0548 Acc:98.70% Time:0.3892s
Training:Epoch[007/030] Iteration[014/014] Loss: 0.0091 Acc:98.82% Time:0.3751s
Test:	 Epoch[007/030] Iteration[004/004] Acc:91.27%

The learning rate for epoch 7 is [0.000285, 0.000765, 0.000794, 0.000707, 0.0008, 0.000796, 0.000916, 0.000829, 0.000846, 0.009807]
Training:Epoch[008/030] Iteration[002/014] Loss: 0.0205 Acc:99.22% Time:0.3872s
Training:Epoch[008/030] Iteration[004/014] Loss: 0.0694 Acc:98.44% Time:0.3799s
Training:Epoch[008/030] Iteration[006/014] Loss: 0.0127 Acc:98.83% Time:0.3862s
Training:Epoch[008/030] Iteration[008/014] Loss: 0.0230 Acc:98.73% Time:0.3861s
Training:Epoch[008/030] Iteration[010/014] Loss: 0.0019 Acc:98.98% Time:0.3798s
Training:Epoch[008/030] Iteration[012/014] Loss: 0.0772 Acc:98.89% Time:0.3790s
Training:Epoch[008/030] Iteration[014/014] Loss: 0.0032 Acc:99.00% Time:0.3598s
Test:	 Epoch[008/030] Iteration[004/004] Acc:84.67%

The learning rate for epoch 8 is [0.000295, 0.000752, 0.000793, 0.000709, 0.00081, 0.000793, 0.000903, 0.00081, 0.000839, 0.00799]
Training:Epoch[009/030] Iteration[002/014] Loss: 0.0167 Acc:99.22% Time:0.3820s
Training:Epoch[009/030] Iteration[004/014] Loss: 0.0287 Acc:99.22% Time:0.3827s
Training:Epoch[009/030] Iteration[006/014] Loss: 0.0334 Acc:99.09% Time:0.3886s
Training:Epoch[009/030] Iteration[008/014] Loss: 0.0196 Acc:99.12% Time:0.3879s
Training:Epoch[009/030] Iteration[010/014] Loss: 0.0025 Acc:99.30% Time:0.3854s
Training:Epoch[009/030] Iteration[012/014] Loss: 0.0224 Acc:99.35% Time:0.3680s
Training:Epoch[009/030] Iteration[014/014] Loss: 0.0024 Acc:99.41% Time:0.3730s
Test:	 Epoch[009/030] Iteration[004/004] Acc:91.04%

The learning rate for epoch 9 is [0.000276, 0.000735, 0.000777, 0.000696, 0.000812, 0.000782, 0.000896, 0.0008, 0.000834, 0.008204]
Training:Epoch[010/030] Iteration[002/014] Loss: 0.0033 Acc:100.00% Time:0.4593s
Training:Epoch[010/030] Iteration[004/014] Loss: 0.0068 Acc:99.80% Time:0.3410s
Training:Epoch[010/030] Iteration[006/014] Loss: 0.0028 Acc:99.87% Time:0.3827s
Training:Epoch[010/030] Iteration[008/014] Loss: 0.0138 Acc:99.71% Time:0.3802s
Training:Epoch[010/030] Iteration[010/014] Loss: 0.0050 Acc:99.69% Time:0.3836s
Training:Epoch[010/030] Iteration[012/014] Loss: 0.0004 Acc:99.74% Time:0.3727s
Training:Epoch[010/030] Iteration[014/014] Loss: 0.4805 Acc:99.53% Time:0.3634s
Test:	 Epoch[010/030] Iteration[004/004] Acc:94.81%

The learning rate for epoch 10 is [0.00039, 0.000688, 0.000787, 0.000708, 0.000814, 0.000792, 0.00092, 0.000802, 0.000782, 0.002829]
Training:Epoch[011/030] Iteration[002/014] Loss: 0.0386 Acc:99.22% Time:0.4348s
Training:Epoch[011/030] Iteration[004/014] Loss: 0.1413 Acc:97.46% Time:0.3656s
Training:Epoch[011/030] Iteration[006/014] Loss: 0.1666 Acc:96.22% Time:0.3852s
Training:Epoch[011/030] Iteration[008/014] Loss: 0.0955 Acc:96.58% Time:0.3865s
Training:Epoch[011/030] Iteration[010/014] Loss: 0.0422 Acc:97.03% Time:0.3872s
Training:Epoch[011/030] Iteration[012/014] Loss: 0.1525 Acc:96.94% Time:0.3741s
Training:Epoch[011/030] Iteration[014/014] Loss: 0.0545 Acc:97.04% Time:0.3823s
Test:	 Epoch[011/030] Iteration[004/004] Acc:80.90%

The learning rate for epoch 11 is [0.00024, 0.000723, 0.000801, 0.000683, 0.000775, 0.000769, 0.000917, 0.000795, 0.000775, 0.0033]
Training:Epoch[012/030] Iteration[002/014] Loss: 0.0131 Acc:100.00% Time:0.3719s
Training:Epoch[012/030] Iteration[004/014] Loss: 0.0243 Acc:99.80% Time:0.3840s
Training:Epoch[012/030] Iteration[006/014] Loss: 0.0754 Acc:99.09% Time:0.3760s
Training:Epoch[012/030] Iteration[008/014] Loss: 0.0740 Acc:98.83% Time:0.3736s
Training:Epoch[012/030] Iteration[010/014] Loss: 0.0237 Acc:98.91% Time:0.3666s
Training:Epoch[012/030] Iteration[012/014] Loss: 0.0657 Acc:98.76% Time:0.3739s
Training:Epoch[012/030] Iteration[014/014] Loss: 0.0632 Acc:98.82% Time:0.3806s
Test:	 Epoch[012/030] Iteration[004/004] Acc:81.13%

The learning rate for epoch 12 is [0.000193, 0.000704, 0.000795, 0.000685, 0.000772, 0.000764, 0.000912, 0.000783, 0.000766, 0.003441]
Training:Epoch[013/030] Iteration[002/014] Loss: 0.0360 Acc:98.44% Time:0.3850s
Training:Epoch[013/030] Iteration[004/014] Loss: 0.0819 Acc:98.24% Time:0.3835s
Training:Epoch[013/030] Iteration[006/014] Loss: 0.0138 Acc:98.70% Time:0.3863s
Training:Epoch[013/030] Iteration[008/014] Loss: 0.0547 Acc:98.63% Time:0.3786s
Training:Epoch[013/030] Iteration[010/014] Loss: 0.0463 Acc:98.67% Time:0.4101s
Training:Epoch[013/030] Iteration[012/014] Loss: 0.0406 Acc:98.63% Time:0.3846s
Training:Epoch[013/030] Iteration[014/014] Loss: 0.0103 Acc:98.76% Time:0.3695s
Test:	 Epoch[013/030] Iteration[004/004] Acc:80.66%

The learning rate for epoch 13 is [0.000212, 0.000746, 0.000815, 0.000719, 0.000817, 0.000794, 0.000912, 0.000782, 0.000761, 0.003409]
Training:Epoch[014/030] Iteration[002/014] Loss: 0.0041 Acc:100.00% Time:0.3643s
Training:Epoch[014/030] Iteration[004/014] Loss: 0.0178 Acc:99.80% Time:0.3606s
Training:Epoch[014/030] Iteration[006/014] Loss: 0.0361 Acc:99.61% Time:0.4194s
Training:Epoch[014/030] Iteration[008/014] Loss: 0.0254 Acc:99.41% Time:0.3750s
Training:Epoch[014/030] Iteration[010/014] Loss: 0.0052 Acc:99.53% Time:0.3851s
Training:Epoch[014/030] Iteration[012/014] Loss: 0.0080 Acc:99.54% Time:0.3726s
Training:Epoch[014/030] Iteration[014/014] Loss: 0.0934 Acc:99.41% Time:0.3930s
Test:	 Epoch[014/030] Iteration[004/004] Acc:91.75%

The learning rate for epoch 14 is [0.000257, 0.00073, 0.000797, 0.00069, 0.000778, 0.000772, 0.000909, 0.000775, 0.000757, 0.003182]
Training:Epoch[015/030] Iteration[002/014] Loss: 0.0151 Acc:99.22% Time:0.3856s
Training:Epoch[015/030] Iteration[004/014] Loss: 0.0501 Acc:98.44% Time:0.3766s
Training:Epoch[015/030] Iteration[006/014] Loss: 0.0361 Acc:98.57% Time:0.3828s
Training:Epoch[015/030] Iteration[008/014] Loss: 0.0422 Acc:98.63% Time:0.3762s
Training:Epoch[015/030] Iteration[010/014] Loss: 0.0111 Acc:98.83% Time:0.3734s
Training:Epoch[015/030] Iteration[012/014] Loss: 0.0033 Acc:99.02% Time:0.3700s
Training:Epoch[015/030] Iteration[014/014] Loss: 0.0087 Acc:99.11% Time:0.3740s
Test:	 Epoch[015/030] Iteration[004/004] Acc:92.69%

The learning rate for epoch 15 is [0.000252, 0.000638, 0.000723, 0.000569, 0.00071, 0.000723, 0.000894, 0.000762, 0.000756, 0.003082]
Training:Epoch[016/030] Iteration[002/014] Loss: 0.0335 Acc:98.83% Time:0.3693s
Training:Epoch[016/030] Iteration[004/014] Loss: 0.0021 Acc:99.41% Time:0.3833s
Training:Epoch[016/030] Iteration[006/014] Loss: 0.0460 Acc:99.22% Time:0.3861s
Training:Epoch[016/030] Iteration[008/014] Loss: 0.0080 Acc:99.32% Time:0.3690s
Training:Epoch[016/030] Iteration[010/014] Loss: 0.0364 Acc:99.14% Time:0.3852s
Training:Epoch[016/030] Iteration[012/014] Loss: 0.0129 Acc:99.22% Time:0.3897s
Training:Epoch[016/030] Iteration[014/014] Loss: 0.0116 Acc:99.23% Time:0.3716s
Test:	 Epoch[016/030] Iteration[004/004] Acc:94.10%

The learning rate for epoch 16 is [0.000264, 0.00058, 0.000698, 0.000547, 0.000705, 0.000706, 0.000883, 0.000748, 0.000749, 0.003072]
Training:Epoch[017/030] Iteration[002/014] Loss: 0.0009 Acc:100.00% Time:0.3830s
Training:Epoch[017/030] Iteration[004/014] Loss: 0.0032 Acc:100.00% Time:0.3730s
Training:Epoch[017/030] Iteration[006/014] Loss: 0.0467 Acc:99.74% Time:0.4456s
Training:Epoch[017/030] Iteration[008/014] Loss: 0.0033 Acc:99.80% Time:0.3897s
Training:Epoch[017/030] Iteration[010/014] Loss: 0.0038 Acc:99.84% Time:0.4320s
Training:Epoch[017/030] Iteration[012/014] Loss: 0.0023 Acc:99.87% Time:0.3705s
Training:Epoch[017/030] Iteration[014/014] Loss: 0.1090 Acc:99.76% Time:0.4269s
Test:	 Epoch[017/030] Iteration[004/004] Acc:94.58%

The learning rate for epoch 17 is [0.000456, 0.00057, 0.000698, 0.000533, 0.000687, 0.000695, 0.000885, 0.000751, 0.00075, 0.002785]
Training:Epoch[018/030] Iteration[002/014] Loss: 0.0597 Acc:98.83% Time:0.3620s
Training:Epoch[018/030] Iteration[004/014] Loss: 0.0227 Acc:98.83% Time:0.3720s
Training:Epoch[018/030] Iteration[006/014] Loss: 0.0546 Acc:98.70% Time:0.4255s
Training:Epoch[018/030] Iteration[008/014] Loss: 0.0401 Acc:98.63% Time:0.3693s
Training:Epoch[018/030] Iteration[010/014] Loss: 0.0779 Acc:98.44% Time:0.3829s
Training:Epoch[018/030] Iteration[012/014] Loss: 0.0836 Acc:98.37% Time:0.3893s
Training:Epoch[018/030] Iteration[014/014] Loss: 0.0615 Acc:98.40% Time:0.3674s
Test:	 Epoch[018/030] Iteration[004/004] Acc:87.97%

The learning rate for epoch 18 is [1e-06, 0.000543, 0.000693, 0.000533, 0.000689, 0.000714, 0.000889, 0.000748, 0.000747, 0.003093]
Training:Epoch[019/030] Iteration[002/014] Loss: 0.0172 Acc:100.00% Time:0.3868s
Training:Epoch[019/030] Iteration[004/014] Loss: 0.0069 Acc:100.00% Time:0.3752s
Training:Epoch[019/030] Iteration[006/014] Loss: 0.0336 Acc:99.48% Time:0.3975s
Training:Epoch[019/030] Iteration[008/014] Loss: 0.0784 Acc:99.12% Time:0.3661s
Training:Epoch[019/030] Iteration[010/014] Loss: 0.0411 Acc:99.06% Time:0.3752s
Training:Epoch[019/030] Iteration[012/014] Loss: 0.0180 Acc:99.02% Time:0.3916s
Training:Epoch[019/030] Iteration[014/014] Loss: 0.0100 Acc:99.11% Time:0.3704s
Test:	 Epoch[019/030] Iteration[004/004] Acc:86.32%

The learning rate for epoch 19 is [1e-06, 0.00051, 0.000679, 0.000527, 0.000681, 0.000708, 0.000886, 0.000743, 0.000749, 0.002612]
Training:Epoch[020/030] Iteration[002/014] Loss: 0.0102 Acc:99.61% Time:0.3835s
Training:Epoch[020/030] Iteration[004/014] Loss: 0.0108 Acc:99.61% Time:0.3739s
Training:Epoch[020/030] Iteration[006/014] Loss: 0.0188 Acc:99.48% Time:0.3832s
Training:Epoch[020/030] Iteration[008/014] Loss: 0.0194 Acc:99.51% Time:0.3853s
Training:Epoch[020/030] Iteration[010/014] Loss: 0.0030 Acc:99.61% Time:0.3740s
Training:Epoch[020/030] Iteration[012/014] Loss: 0.0460 Acc:99.48% Time:0.3840s
Training:Epoch[020/030] Iteration[014/014] Loss: 0.0090 Acc:99.47% Time:0.3829s
Test:	 Epoch[020/030] Iteration[004/004] Acc:92.45%

The learning rate for epoch 20 is [1e-06, 0.000477, 0.000662, 0.000503, 0.000666, 0.000685, 0.00088, 0.000733, 0.000749, 0.002758]
Training:Epoch[021/030] Iteration[002/014] Loss: 0.0006 Acc:100.00% Time:0.3840s
Training:Epoch[021/030] Iteration[004/014] Loss: 0.0006 Acc:100.00% Time:0.3859s
Training:Epoch[021/030] Iteration[006/014] Loss: 0.0216 Acc:99.61% Time:0.3902s
Training:Epoch[021/030] Iteration[008/014] Loss: 0.0007 Acc:99.71% Time:0.3811s
Training:Epoch[021/030] Iteration[010/014] Loss: 0.0043 Acc:99.69% Time:0.3957s
Training:Epoch[021/030] Iteration[012/014] Loss: 0.0170 Acc:99.67% Time:0.3656s
Training:Epoch[021/030] Iteration[014/014] Loss: 0.0032 Acc:99.70% Time:0.3860s
Test:	 Epoch[021/030] Iteration[004/004] Acc:92.69%

The learning rate for epoch 21 is [1e-06, 0.000481, 0.000666, 0.00051, 0.000675, 0.000689, 0.00088, 0.000732, 0.000749, 0.002744]
Training:Epoch[022/030] Iteration[002/014] Loss: 0.0136 Acc:99.22% Time:0.3849s
Training:Epoch[022/030] Iteration[004/014] Loss: 0.0021 Acc:99.61% Time:0.3685s
Training:Epoch[022/030] Iteration[006/014] Loss: 0.0044 Acc:99.74% Time:0.4593s
Training:Epoch[022/030] Iteration[008/014] Loss: 0.0012 Acc:99.80% Time:0.3728s
Training:Epoch[022/030] Iteration[010/014] Loss: 0.0007 Acc:99.84% Time:0.3751s
Training:Epoch[022/030] Iteration[012/014] Loss: 0.0109 Acc:99.80% Time:0.3858s
Training:Epoch[022/030] Iteration[014/014] Loss: 0.0011 Acc:99.82% Time:0.4091s
Test:	 Epoch[022/030] Iteration[004/004] Acc:90.80%

The learning rate for epoch 22 is [1e-06, 0.000475, 0.000663, 0.000506, 0.000671, 0.000686, 0.000879, 0.00073, 0.00075, 0.002863]
Training:Epoch[023/030] Iteration[002/014] Loss: 0.0006 Acc:100.00% Time:0.3625s
Training:Epoch[023/030] Iteration[004/014] Loss: 0.0034 Acc:100.00% Time:0.3379s
Training:Epoch[023/030] Iteration[006/014] Loss: 0.0205 Acc:99.87% Time:0.3856s
Training:Epoch[023/030] Iteration[008/014] Loss: 0.0092 Acc:99.80% Time:0.3849s
Training:Epoch[023/030] Iteration[010/014] Loss: 0.0020 Acc:99.84% Time:0.4029s
Training:Epoch[023/030] Iteration[012/014] Loss: 0.0012 Acc:99.87% Time:0.3659s
Training:Epoch[023/030] Iteration[014/014] Loss: 0.0014 Acc:99.88% Time:0.4046s
Test:	 Epoch[023/030] Iteration[004/004] Acc:91.51%

The learning rate for epoch 23 is [1e-06, 0.000476, 0.000665, 0.000507, 0.00067, 0.000685, 0.000879, 0.000731, 0.00075, 0.002799]
Training:Epoch[024/030] Iteration[002/014] Loss: 0.0011 Acc:100.00% Time:0.3925s
Training:Epoch[024/030] Iteration[004/014] Loss: 0.0004 Acc:100.00% Time:0.3908s
Training:Epoch[024/030] Iteration[006/014] Loss: 0.0003 Acc:100.00% Time:0.3695s
Training:Epoch[024/030] Iteration[008/014] Loss: 0.0008 Acc:100.00% Time:0.3906s
Training:Epoch[024/030] Iteration[010/014] Loss: 0.0020 Acc:100.00% Time:0.3831s
Training:Epoch[024/030] Iteration[012/014] Loss: 0.0067 Acc:99.93% Time:0.3830s
Training:Epoch[024/030] Iteration[014/014] Loss: 0.0011 Acc:99.94% Time:0.3856s
Test:	 Epoch[024/030] Iteration[004/004] Acc:91.75%

The learning rate for epoch 24 is [1e-06, 0.000483, 0.000664, 0.000506, 0.00067, 0.000684, 0.000878, 0.00073, 0.00075, 0.002839]
Training:Epoch[025/030] Iteration[002/014] Loss: 0.0014 Acc:100.00% Time:0.3727s
Training:Epoch[025/030] Iteration[004/014] Loss: 0.0003 Acc:100.00% Time:0.3677s
Training:Epoch[025/030] Iteration[006/014] Loss: 0.0005 Acc:100.00% Time:0.3834s
Training:Epoch[025/030] Iteration[008/014] Loss: 0.0005 Acc:100.00% Time:0.3849s
Training:Epoch[025/030] Iteration[010/014] Loss: 0.0002 Acc:100.00% Time:0.3724s
Training:Epoch[025/030] Iteration[012/014] Loss: 0.0003 Acc:100.00% Time:0.3602s
Training:Epoch[025/030] Iteration[014/014] Loss: 0.0012 Acc:100.00% Time:0.3981s
Test:	 Epoch[025/030] Iteration[004/004] Acc:91.27%

The learning rate for epoch 25 is [1e-06, 0.000482, 0.000664, 0.000506, 0.00067, 0.000685, 0.000878, 0.00073, 0.00075, 0.002848]
Training:Epoch[026/030] Iteration[002/014] Loss: 0.0005 Acc:100.00% Time:0.3313s
Training:Epoch[026/030] Iteration[004/014] Loss: 0.0005 Acc:100.00% Time:0.3751s
Training:Epoch[026/030] Iteration[006/014] Loss: 0.0150 Acc:99.74% Time:0.3831s
Training:Epoch[026/030] Iteration[008/014] Loss: 0.0003 Acc:99.80% Time:0.3818s
Training:Epoch[026/030] Iteration[010/014] Loss: 0.0002 Acc:99.84% Time:0.3875s
Training:Epoch[026/030] Iteration[012/014] Loss: 0.0002 Acc:99.87% Time:0.3696s
Training:Epoch[026/030] Iteration[014/014] Loss: 0.0010 Acc:99.88% Time:0.3694s
Test:	 Epoch[026/030] Iteration[004/004] Acc:90.33%

The learning rate for epoch 26 is [1e-06, 0.000486, 0.000667, 0.000506, 0.000668, 0.000683, 0.000877, 0.000729, 0.000751, 0.002881]
Training:Epoch[027/030] Iteration[002/014] Loss: 0.0002 Acc:100.00% Time:0.3755s
Training:Epoch[027/030] Iteration[004/014] Loss: 0.0001 Acc:100.00% Time:0.3855s
Training:Epoch[027/030] Iteration[006/014] Loss: 0.0003 Acc:100.00% Time:0.3748s
Training:Epoch[027/030] Iteration[008/014] Loss: 0.0173 Acc:99.80% Time:0.3651s
Training:Epoch[027/030] Iteration[010/014] Loss: 0.0007 Acc:99.84% Time:0.3741s
Training:Epoch[027/030] Iteration[012/014] Loss: 0.0001 Acc:99.87% Time:0.3744s
Training:Epoch[027/030] Iteration[014/014] Loss: 0.0029 Acc:99.88% Time:0.3742s
Test:	 Epoch[027/030] Iteration[004/004] Acc:90.80%

The learning rate for epoch 27 is [1e-06, 0.000454, 0.000658, 0.000504, 0.00067, 0.000687, 0.000878, 0.00073, 0.000751, 0.002865]
Training:Epoch[028/030] Iteration[002/014] Loss: 0.0130 Acc:99.22% Time:0.3818s
Training:Epoch[028/030] Iteration[004/014] Loss: 0.0005 Acc:99.61% Time:0.3694s
Training:Epoch[028/030] Iteration[006/014] Loss: 0.0091 Acc:99.61% Time:0.3968s
Training:Epoch[028/030] Iteration[008/014] Loss: 0.0121 Acc:99.51% Time:0.3844s
Training:Epoch[028/030] Iteration[010/014] Loss: 0.0003 Acc:99.61% Time:0.3692s
Training:Epoch[028/030] Iteration[012/014] Loss: 0.0033 Acc:99.67% Time:0.3683s
Training:Epoch[028/030] Iteration[014/014] Loss: 0.0188 Acc:99.70% Time:0.3845s
Test:	 Epoch[028/030] Iteration[004/004] Acc:91.75%

The learning rate for epoch 28 is [1e-06, 0.000461, 0.000662, 0.000507, 0.000673, 0.000695, 0.000878, 0.000728, 0.000748, 0.002757]
Training:Epoch[029/030] Iteration[002/014] Loss: 0.0010 Acc:100.00% Time:0.3729s
Training:Epoch[029/030] Iteration[004/014] Loss: 0.0070 Acc:99.80% Time:0.3822s
Training:Epoch[029/030] Iteration[006/014] Loss: 0.0093 Acc:99.74% Time:0.3855s
Training:Epoch[029/030] Iteration[008/014] Loss: 0.0228 Acc:99.61% Time:0.3732s
Training:Epoch[029/030] Iteration[010/014] Loss: 0.0019 Acc:99.69% Time:0.3864s
Training:Epoch[029/030] Iteration[012/014] Loss: 0.0007 Acc:99.74% Time:0.3797s
Training:Epoch[029/030] Iteration[014/014] Loss: 0.0717 Acc:99.70% Time:0.3764s
Test:	 Epoch[029/030] Iteration[004/004] Acc:93.16%

The learning rate for epoch 29 is [1e-06, 0.000502, 0.000684, 0.000506, 0.000696, 0.000726, 0.000887, 0.000738, 0.000753, 0.002738]
Training:Epoch[030/030] Iteration[002/014] Loss: 0.0002 Acc:100.00% Time:0.3770s
Training:Epoch[030/030] Iteration[004/014] Loss: 0.0366 Acc:99.61% Time:0.3846s
Training:Epoch[030/030] Iteration[006/014] Loss: 0.0096 Acc:99.61% Time:0.3884s
Training:Epoch[030/030] Iteration[008/014] Loss: 0.0250 Acc:99.61% Time:0.3888s
Training:Epoch[030/030] Iteration[010/014] Loss: 0.0033 Acc:99.69% Time:0.3868s
Training:Epoch[030/030] Iteration[012/014] Loss: 0.0039 Acc:99.74% Time:0.3863s
Training:Epoch[030/030] Iteration[014/014] Loss: 0.0033 Acc:99.76% Time:0.3839s
Test:	 Epoch[030/030] Iteration[004/004] Acc:91.04%

The learning rate for epoch 30 is [1e-06, 0.00053, 0.000682, 0.000496, 0.000681, 0.00072, 0.000886, 0.000736, 0.000752, 0.00272]

Training finish, the time consumption of 30 epochs is 242s

The max testing accuracy is: 94.81%, reached at epoch 10.


====================The training of fold 5 start.====================

The self-supervised trained parameters are loaded.


Training start!

Training:Epoch[001/030] Iteration[002/013] Loss: 0.8207 Acc:61.72% Time:0.3766s
Training:Epoch[001/030] Iteration[004/013] Loss: 0.4706 Acc:71.68% Time:0.3825s
Training:Epoch[001/030] Iteration[006/013] Loss: 0.1846 Acc:78.78% Time:0.3924s
Training:Epoch[001/030] Iteration[008/013] Loss: 0.3593 Acc:81.64% Time:0.3693s
Training:Epoch[001/030] Iteration[010/013] Loss: 0.1891 Acc:83.91% Time:0.3908s
Training:Epoch[001/030] Iteration[012/013] Loss: 0.1382 Acc:86.00% Time:0.3939s
Test:	 Epoch[001/030] Iteration[004/004] Acc:70.80%

The learning rate for epoch 1 is [0.001398, 0.00137, 0.001127, 0.001098, 0.001082, 0.001117, 0.001104, 0.001122, 0.001034, 0.01]
Training:Epoch[002/030] Iteration[002/013] Loss: 0.1985 Acc:94.14% Time:0.3873s
Training:Epoch[002/030] Iteration[004/013] Loss: 0.1406 Acc:94.73% Time:0.3847s
Training:Epoch[002/030] Iteration[006/013] Loss: 0.0549 Acc:95.83% Time:0.3668s
Training:Epoch[002/030] Iteration[008/013] Loss: 0.1048 Acc:96.09% Time:0.3686s
Training:Epoch[002/030] Iteration[010/013] Loss: 0.0580 Acc:96.56% Time:0.3854s
Training:Epoch[002/030] Iteration[012/013] Loss: 0.0779 Acc:96.88% Time:0.3531s
Test:	 Epoch[002/030] Iteration[004/004] Acc:55.46%

The learning rate for epoch 2 is [0.001654, 0.00147, 0.001145, 0.00114, 0.001104, 0.001137, 0.001088, 0.001122, 0.001023, 0.01]
Training:Epoch[003/030] Iteration[002/013] Loss: 0.0805 Acc:97.27% Time:0.3598s
Training:Epoch[003/030] Iteration[004/013] Loss: 0.0584 Acc:97.27% Time:0.3684s
Training:Epoch[003/030] Iteration[006/013] Loss: 0.0501 Acc:97.53% Time:0.4613s
Training:Epoch[003/030] Iteration[008/013] Loss: 0.0335 Acc:97.85% Time:0.3929s
Training:Epoch[003/030] Iteration[010/013] Loss: 0.0280 Acc:98.05% Time:0.4144s
Training:Epoch[003/030] Iteration[012/013] Loss: 0.0570 Acc:98.11% Time:0.3789s
Test:	 Epoch[003/030] Iteration[004/004] Acc:85.92%

The learning rate for epoch 3 is [0.001486, 0.001427, 0.001104, 0.001117, 0.001079, 0.001122, 0.001083, 0.001133, 0.001032, 0.01]
Training:Epoch[004/030] Iteration[002/013] Loss: 0.0844 Acc:97.66% Time:0.3711s
Training:Epoch[004/030] Iteration[004/013] Loss: 0.0385 Acc:98.24% Time:0.3638s
Training:Epoch[004/030] Iteration[006/013] Loss: 0.0649 Acc:98.31% Time:0.3755s
Training:Epoch[004/030] Iteration[008/013] Loss: 0.0858 Acc:97.95% Time:0.3703s
Training:Epoch[004/030] Iteration[010/013] Loss: 0.0586 Acc:97.81% Time:0.3683s
Training:Epoch[004/030] Iteration[012/013] Loss: 0.0598 Acc:97.98% Time:0.3754s
Test:	 Epoch[004/030] Iteration[004/004] Acc:91.60%

The learning rate for epoch 4 is [0.001675, 0.001555, 0.001179, 0.001177, 0.001088, 0.001157, 0.001094, 0.001144, 0.00104, 0.01]
Training:Epoch[005/030] Iteration[002/013] Loss: 0.0496 Acc:98.44% Time:0.3953s
Training:Epoch[005/030] Iteration[004/013] Loss: 0.0248 Acc:99.02% Time:0.3954s
Training:Epoch[005/030] Iteration[006/013] Loss: 0.0665 Acc:98.83% Time:0.3754s
Training:Epoch[005/030] Iteration[008/013] Loss: 0.0449 Acc:98.73% Time:0.3630s
Training:Epoch[005/030] Iteration[010/013] Loss: 0.0421 Acc:98.59% Time:0.3358s
Training:Epoch[005/030] Iteration[012/013] Loss: 0.0229 Acc:98.63% Time:0.3687s
Test:	 Epoch[005/030] Iteration[004/004] Acc:90.34%

The learning rate for epoch 5 is [0.001687, 0.001528, 0.001174, 0.001177, 0.001085, 0.001147, 0.001092, 0.001136, 0.001036, 0.01]
Training:Epoch[006/030] Iteration[002/013] Loss: 0.0857 Acc:97.66% Time:0.3448s
Training:Epoch[006/030] Iteration[004/013] Loss: 0.0575 Acc:98.05% Time:0.3845s
Training:Epoch[006/030] Iteration[006/013] Loss: 0.0264 Acc:98.44% Time:0.3829s
Training:Epoch[006/030] Iteration[008/013] Loss: 0.0295 Acc:98.44% Time:0.3806s
Training:Epoch[006/030] Iteration[010/013] Loss: 0.0381 Acc:98.36% Time:0.3761s
Training:Epoch[006/030] Iteration[012/013] Loss: 0.0375 Acc:98.44% Time:0.3879s
Test:	 Epoch[006/030] Iteration[004/004] Acc:89.50%

The learning rate for epoch 6 is [0.002125, 0.001673, 0.001212, 0.001183, 0.001069, 0.001152, 0.001094, 0.001142, 0.001031, 0.009732]
Training:Epoch[007/030] Iteration[002/013] Loss: 0.0142 Acc:99.22% Time:0.3862s
Training:Epoch[007/030] Iteration[004/013] Loss: 0.0454 Acc:99.22% Time:0.3638s
Training:Epoch[007/030] Iteration[006/013] Loss: 0.0354 Acc:99.22% Time:0.3680s
Training:Epoch[007/030] Iteration[008/013] Loss: 0.0307 Acc:99.02% Time:0.3863s
Training:Epoch[007/030] Iteration[010/013] Loss: 0.1041 Acc:98.36% Time:0.4342s
Training:Epoch[007/030] Iteration[012/013] Loss: 0.0513 Acc:98.37% Time:0.3890s
Test:	 Epoch[007/030] Iteration[004/004] Acc:81.93%

The learning rate for epoch 7 is [0.002665, 0.001675, 0.00118, 0.00111, 0.001035, 0.001114, 0.001078, 0.001114, 0.001011, 0.008648]
Training:Epoch[008/030] Iteration[002/013] Loss: 0.0556 Acc:98.05% Time:0.3858s
Training:Epoch[008/030] Iteration[004/013] Loss: 0.0769 Acc:98.05% Time:0.3871s
Training:Epoch[008/030] Iteration[006/013] Loss: 0.0422 Acc:98.05% Time:0.4490s
Training:Epoch[008/030] Iteration[008/013] Loss: 0.0258 Acc:98.34% Time:0.3744s
Training:Epoch[008/030] Iteration[010/013] Loss: 0.0209 Acc:98.52% Time:0.3892s
Training:Epoch[008/030] Iteration[012/013] Loss: 0.0663 Acc:98.44% Time:0.3848s
Test:	 Epoch[008/030] Iteration[004/004] Acc:86.55%

The learning rate for epoch 8 is [0.00247, 0.001496, 0.001101, 0.001022, 0.000972, 0.00107, 0.001063, 0.001103, 0.00101, 0.008965]
Training:Epoch[009/030] Iteration[002/013] Loss: 0.0259 Acc:98.83% Time:0.3826s
Training:Epoch[009/030] Iteration[004/013] Loss: 0.0248 Acc:99.22% Time:0.3653s
Training:Epoch[009/030] Iteration[006/013] Loss: 0.0228 Acc:99.22% Time:0.3868s
Training:Epoch[009/030] Iteration[008/013] Loss: 0.0207 Acc:99.22% Time:0.3723s
Training:Epoch[009/030] Iteration[010/013] Loss: 0.0187 Acc:99.30% Time:0.3851s
Training:Epoch[009/030] Iteration[012/013] Loss: 0.0310 Acc:99.22% Time:0.3858s
Test:	 Epoch[009/030] Iteration[004/004] Acc:86.97%

The learning rate for epoch 9 is [0.002478, 0.001498, 0.00111, 0.001039, 0.000993, 0.0011, 0.00107, 0.001105, 0.001006, 0.008267]
Training:Epoch[010/030] Iteration[002/013] Loss: 0.0391 Acc:98.44% Time:0.3877s
Training:Epoch[010/030] Iteration[004/013] Loss: 0.0165 Acc:98.83% Time:0.3904s
Training:Epoch[010/030] Iteration[006/013] Loss: 0.0419 Acc:98.83% Time:0.3807s
Training:Epoch[010/030] Iteration[008/013] Loss: 0.0398 Acc:98.73% Time:0.3668s
Training:Epoch[010/030] Iteration[010/013] Loss: 0.0343 Acc:98.59% Time:0.3856s
Training:Epoch[010/030] Iteration[012/013] Loss: 0.0420 Acc:98.63% Time:0.3684s
Test:	 Epoch[010/030] Iteration[004/004] Acc:83.40%

The learning rate for epoch 10 is [0.002237, 0.001432, 0.001075, 0.001008, 0.000979, 0.001086, 0.001061, 0.001098, 0.001001, 0.009026]
Training:Epoch[011/030] Iteration[002/013] Loss: 0.0419 Acc:98.05% Time:0.4068s
Training:Epoch[011/030] Iteration[004/013] Loss: 0.0343 Acc:98.24% Time:0.3842s
Training:Epoch[011/030] Iteration[006/013] Loss: 0.0196 Acc:98.44% Time:0.3621s
Training:Epoch[011/030] Iteration[008/013] Loss: 0.0818 Acc:98.05% Time:0.3763s
Training:Epoch[011/030] Iteration[010/013] Loss: 0.0577 Acc:98.05% Time:0.3662s
Training:Epoch[011/030] Iteration[012/013] Loss: 0.0181 Acc:98.24% Time:0.3599s
Test:	 Epoch[011/030] Iteration[004/004] Acc:77.10%

The learning rate for epoch 11 is [0.0022, 0.001564, 0.001153, 0.001042, 0.000991, 0.001088, 0.00106, 0.001095, 0.000996, 0.008492]
Training:Epoch[012/030] Iteration[002/013] Loss: 0.0504 Acc:98.44% Time:0.3699s
Training:Epoch[012/030] Iteration[004/013] Loss: 0.0317 Acc:98.24% Time:0.3872s
Training:Epoch[012/030] Iteration[006/013] Loss: 0.0739 Acc:98.18% Time:0.4069s
Training:Epoch[012/030] Iteration[008/013] Loss: 0.0720 Acc:97.95% Time:0.3670s
Training:Epoch[012/030] Iteration[010/013] Loss: 0.0966 Acc:97.58% Time:0.3714s
Training:Epoch[012/030] Iteration[012/013] Loss: 0.0734 Acc:97.46% Time:0.3877s
Test:	 Epoch[012/030] Iteration[004/004] Acc:74.16%

The learning rate for epoch 12 is [0.00232, 0.001664, 0.001193, 0.00109, 0.001011, 0.001116, 0.001067, 0.001092, 0.000996, 0.008914]
Training:Epoch[013/030] Iteration[002/013] Loss: 0.0381 Acc:98.44% Time:0.3681s
Training:Epoch[013/030] Iteration[004/013] Loss: 0.0468 Acc:98.44% Time:0.3851s
Training:Epoch[013/030] Iteration[006/013] Loss: 0.0312 Acc:98.44% Time:0.3853s
Training:Epoch[013/030] Iteration[008/013] Loss: 0.0550 Acc:98.34% Time:0.3517s
Training:Epoch[013/030] Iteration[010/013] Loss: 0.0438 Acc:98.28% Time:0.3817s
Training:Epoch[013/030] Iteration[012/013] Loss: 0.0329 Acc:98.37% Time:0.3591s
Test:	 Epoch[013/030] Iteration[004/004] Acc:85.71%

The learning rate for epoch 13 is [0.002417, 0.001702, 0.001209, 0.001121, 0.001056, 0.001167, 0.001084, 0.001105, 0.000996, 0.008924]
Training:Epoch[014/030] Iteration[002/013] Loss: 0.0333 Acc:98.83% Time:0.3971s
Training:Epoch[014/030] Iteration[004/013] Loss: 0.0863 Acc:98.44% Time:0.3843s
Training:Epoch[014/030] Iteration[006/013] Loss: 0.0144 Acc:98.83% Time:0.3857s
Training:Epoch[014/030] Iteration[008/013] Loss: 0.0250 Acc:98.83% Time:0.3868s
Training:Epoch[014/030] Iteration[010/013] Loss: 0.0390 Acc:98.59% Time:0.3723s
Training:Epoch[014/030] Iteration[012/013] Loss: 0.0330 Acc:98.63% Time:0.3709s
Test:	 Epoch[014/030] Iteration[004/004] Acc:81.09%

The learning rate for epoch 14 is [0.002267, 0.001654, 0.001218, 0.001083, 0.001052, 0.001166, 0.001089, 0.001107, 0.000994, 0.007908]
Training:Epoch[015/030] Iteration[002/013] Loss: 0.0101 Acc:99.61% Time:0.3871s
Training:Epoch[015/030] Iteration[004/013] Loss: 0.0571 Acc:98.63% Time:0.3847s
Training:Epoch[015/030] Iteration[006/013] Loss: 0.0198 Acc:98.83% Time:0.3842s
Training:Epoch[015/030] Iteration[008/013] Loss: 0.0494 Acc:98.83% Time:0.3846s
Training:Epoch[015/030] Iteration[010/013] Loss: 0.0251 Acc:98.67% Time:0.3658s
Training:Epoch[015/030] Iteration[012/013] Loss: 0.0383 Acc:98.70% Time:0.4709s
Test:	 Epoch[015/030] Iteration[004/004] Acc:81.93%

The learning rate for epoch 15 is [0.002208, 0.001664, 0.001245, 0.001089, 0.001049, 0.001166, 0.001088, 0.00111, 0.001, 0.008477]
Training:Epoch[016/030] Iteration[002/013] Loss: 0.0161 Acc:99.61% Time:0.4343s
Training:Epoch[016/030] Iteration[004/013] Loss: 0.0132 Acc:99.80% Time:0.3920s
Training:Epoch[016/030] Iteration[006/013] Loss: 0.0590 Acc:99.09% Time:0.3820s
Training:Epoch[016/030] Iteration[008/013] Loss: 0.0701 Acc:98.63% Time:0.3855s
Training:Epoch[016/030] Iteration[010/013] Loss: 0.0383 Acc:98.67% Time:0.3878s
Training:Epoch[016/030] Iteration[012/013] Loss: 0.0103 Acc:98.76% Time:0.3871s
Test:	 Epoch[016/030] Iteration[004/004] Acc:87.61%

The learning rate for epoch 16 is [0.002194, 0.001668, 0.001241, 0.001104, 0.00106, 0.001174, 0.001088, 0.001109, 0.000997, 0.008334]
Training:Epoch[017/030] Iteration[002/013] Loss: 0.0315 Acc:98.83% Time:0.3758s
Training:Epoch[017/030] Iteration[004/013] Loss: 0.0195 Acc:98.83% Time:0.3688s
Training:Epoch[017/030] Iteration[006/013] Loss: 0.0444 Acc:98.31% Time:0.3862s
Training:Epoch[017/030] Iteration[008/013] Loss: 0.0409 Acc:97.95% Time:0.3810s
Training:Epoch[017/030] Iteration[010/013] Loss: 0.0303 Acc:98.12% Time:0.3745s
Training:Epoch[017/030] Iteration[012/013] Loss: 0.0247 Acc:98.24% Time:0.3415s
Test:	 Epoch[017/030] Iteration[004/004] Acc:90.76%

The learning rate for epoch 17 is [0.002038, 0.001628, 0.001227, 0.001087, 0.001058, 0.001166, 0.001084, 0.001106, 0.000997, 0.008336]
Training:Epoch[018/030] Iteration[002/013] Loss: 0.0155 Acc:98.44% Time:0.3698s
Training:Epoch[018/030] Iteration[004/013] Loss: 0.0392 Acc:98.05% Time:0.3770s
Training:Epoch[018/030] Iteration[006/013] Loss: 0.0076 Acc:98.57% Time:0.3730s
Training:Epoch[018/030] Iteration[008/013] Loss: 0.0160 Acc:98.83% Time:0.3848s
Training:Epoch[018/030] Iteration[010/013] Loss: 0.0151 Acc:98.91% Time:0.3608s
Training:Epoch[018/030] Iteration[012/013] Loss: 0.0328 Acc:98.89% Time:0.3718s
Test:	 Epoch[018/030] Iteration[004/004] Acc:89.50%

The learning rate for epoch 18 is [0.002154, 0.001758, 0.001287, 0.001133, 0.001082, 0.001189, 0.001088, 0.001111, 0.000999, 0.008352]
Training:Epoch[019/030] Iteration[002/013] Loss: 0.0105 Acc:99.61% Time:0.3724s
Training:Epoch[019/030] Iteration[004/013] Loss: 0.0079 Acc:99.61% Time:0.3728s
Training:Epoch[019/030] Iteration[006/013] Loss: 0.0038 Acc:99.74% Time:0.3823s
Training:Epoch[019/030] Iteration[008/013] Loss: 0.0458 Acc:99.51% Time:0.3910s
Training:Epoch[019/030] Iteration[010/013] Loss: 0.0153 Acc:99.38% Time:0.3837s
Training:Epoch[019/030] Iteration[012/013] Loss: 0.0192 Acc:99.35% Time:0.4748s
Test:	 Epoch[019/030] Iteration[004/004] Acc:89.92%

The learning rate for epoch 19 is [0.002178, 0.001758, 0.001294, 0.001131, 0.001087, 0.001193, 0.001087, 0.001111, 0.000999, 0.008474]
Training:Epoch[020/030] Iteration[002/013] Loss: 0.0067 Acc:100.00% Time:0.3848s
Training:Epoch[020/030] Iteration[004/013] Loss: 0.0015 Acc:100.00% Time:0.3869s
Training:Epoch[020/030] Iteration[006/013] Loss: 0.0778 Acc:99.61% Time:0.3705s
Training:Epoch[020/030] Iteration[008/013] Loss: 0.0239 Acc:99.41% Time:0.3658s
Training:Epoch[020/030] Iteration[010/013] Loss: 0.0134 Acc:99.45% Time:0.3852s
Training:Epoch[020/030] Iteration[012/013] Loss: 0.0375 Acc:99.28% Time:0.3721s
Test:	 Epoch[020/030] Iteration[004/004] Acc:89.71%

The learning rate for epoch 20 is [0.002194, 0.001765, 0.001291, 0.001133, 0.001089, 0.001196, 0.001087, 0.001109, 0.000999, 0.007845]
Training:Epoch[021/030] Iteration[002/013] Loss: 0.0077 Acc:99.61% Time:0.4204s
Training:Epoch[021/030] Iteration[004/013] Loss: 0.0112 Acc:99.61% Time:0.3717s
Training:Epoch[021/030] Iteration[006/013] Loss: 0.0341 Acc:99.22% Time:0.3632s
Training:Epoch[021/030] Iteration[008/013] Loss: 0.0026 Acc:99.41% Time:0.3895s
Training:Epoch[021/030] Iteration[010/013] Loss: 0.0163 Acc:99.30% Time:0.3757s
Training:Epoch[021/030] Iteration[012/013] Loss: 0.0480 Acc:99.22% Time:0.3929s
Test:	 Epoch[021/030] Iteration[004/004] Acc:91.18%

The learning rate for epoch 21 is [0.002156, 0.001755, 0.001281, 0.001123, 0.001084, 0.001192, 0.001086, 0.001108, 0.000998, 0.008286]
Training:Epoch[022/030] Iteration[002/013] Loss: 0.0083 Acc:99.22% Time:0.3723s
Training:Epoch[022/030] Iteration[004/013] Loss: 0.0184 Acc:99.22% Time:0.3791s
Training:Epoch[022/030] Iteration[006/013] Loss: 0.0147 Acc:99.22% Time:0.3834s
Training:Epoch[022/030] Iteration[008/013] Loss: 0.0098 Acc:99.32% Time:0.3912s
Training:Epoch[022/030] Iteration[010/013] Loss: 0.0225 Acc:99.22% Time:0.3672s
Training:Epoch[022/030] Iteration[012/013] Loss: 0.0143 Acc:99.28% Time:0.3760s
Test:	 Epoch[022/030] Iteration[004/004] Acc:90.13%

The learning rate for epoch 22 is [0.002091, 0.001757, 0.001289, 0.001121, 0.001079, 0.001186, 0.001086, 0.001109, 0.000999, 0.00806]
Training:Epoch[023/030] Iteration[002/013] Loss: 0.0024 Acc:100.00% Time:0.3845s
Training:Epoch[023/030] Iteration[004/013] Loss: 0.0134 Acc:99.41% Time:0.3902s
Training:Epoch[023/030] Iteration[006/013] Loss: 0.0123 Acc:99.48% Time:0.3932s
Training:Epoch[023/030] Iteration[008/013] Loss: 0.0199 Acc:99.32% Time:0.3957s
Training:Epoch[023/030] Iteration[010/013] Loss: 0.0268 Acc:99.30% Time:0.3647s
Training:Epoch[023/030] Iteration[012/013] Loss: 0.0585 Acc:99.15% Time:0.3863s
Test:	 Epoch[023/030] Iteration[004/004] Acc:80.88%

The learning rate for epoch 23 is [0.002024, 0.001708, 0.001268, 0.001109, 0.001064, 0.001178, 0.001082, 0.001105, 0.000998, 0.00812]
Training:Epoch[024/030] Iteration[002/013] Loss: 0.0209 Acc:99.22% Time:0.3632s
Training:Epoch[024/030] Iteration[004/013] Loss: 0.0163 Acc:99.22% Time:0.3948s
Training:Epoch[024/030] Iteration[006/013] Loss: 0.0545 Acc:99.09% Time:0.3938s
Training:Epoch[024/030] Iteration[008/013] Loss: 0.0166 Acc:99.02% Time:0.3842s
Training:Epoch[024/030] Iteration[010/013] Loss: 0.0212 Acc:98.91% Time:0.3802s
Training:Epoch[024/030] Iteration[012/013] Loss: 0.0334 Acc:98.76% Time:0.3953s
Test:	 Epoch[024/030] Iteration[004/004] Acc:87.82%

The learning rate for epoch 24 is [0.001939, 0.001706, 0.001254, 0.001091, 0.001066, 0.001168, 0.001083, 0.001102, 0.000998, 0.007974]
Training:Epoch[025/030] Iteration[002/013] Loss: 0.0069 Acc:100.00% Time:0.3827s
Training:Epoch[025/030] Iteration[004/013] Loss: 0.0117 Acc:99.80% Time:0.3944s
Training:Epoch[025/030] Iteration[006/013] Loss: 0.0120 Acc:99.74% Time:0.3893s
Training:Epoch[025/030] Iteration[008/013] Loss: 0.0131 Acc:99.61% Time:0.4107s
Training:Epoch[025/030] Iteration[010/013] Loss: 0.0163 Acc:99.45% Time:0.3737s
Training:Epoch[025/030] Iteration[012/013] Loss: 0.0122 Acc:99.41% Time:0.3837s
Test:	 Epoch[025/030] Iteration[004/004] Acc:89.92%

The learning rate for epoch 25 is [0.001946, 0.001707, 0.001254, 0.001097, 0.001069, 0.001174, 0.001085, 0.001104, 0.000999, 0.00808]
Training:Epoch[026/030] Iteration[002/013] Loss: 0.0177 Acc:98.44% Time:0.3746s
Training:Epoch[026/030] Iteration[004/013] Loss: 0.0062 Acc:99.22% Time:0.3871s
Training:Epoch[026/030] Iteration[006/013] Loss: 0.0148 Acc:99.22% Time:0.3950s
Training:Epoch[026/030] Iteration[008/013] Loss: 0.0353 Acc:99.12% Time:0.3973s
Training:Epoch[026/030] Iteration[010/013] Loss: 0.0074 Acc:99.22% Time:0.3726s
Training:Epoch[026/030] Iteration[012/013] Loss: 0.0071 Acc:99.35% Time:0.3664s
Test:	 Epoch[026/030] Iteration[004/004] Acc:88.03%

The learning rate for epoch 26 is [0.001974, 0.001716, 0.001254, 0.001096, 0.001064, 0.001171, 0.001083, 0.001104, 0.000999, 0.008092]
Training:Epoch[027/030] Iteration[002/013] Loss: 0.0163 Acc:99.22% Time:0.3757s
Training:Epoch[027/030] Iteration[004/013] Loss: 0.0111 Acc:99.41% Time:0.3737s
Training:Epoch[027/030] Iteration[006/013] Loss: 0.0024 Acc:99.61% Time:0.3799s
Training:Epoch[027/030] Iteration[008/013] Loss: 0.0662 Acc:99.12% Time:0.3686s
Training:Epoch[027/030] Iteration[010/013] Loss: 0.0215 Acc:98.98% Time:0.3846s
Training:Epoch[027/030] Iteration[012/013] Loss: 0.0471 Acc:98.83% Time:0.3812s
Test:	 Epoch[027/030] Iteration[004/004] Acc:86.97%

The learning rate for epoch 27 is [0.001992, 0.001713, 0.001245, 0.001088, 0.001062, 0.001173, 0.001083, 0.001104, 0.001, 0.007779]
Training:Epoch[028/030] Iteration[002/013] Loss: 0.0334 Acc:98.83% Time:0.3898s
Training:Epoch[028/030] Iteration[004/013] Loss: 0.0263 Acc:98.83% Time:0.3887s
Training:Epoch[028/030] Iteration[006/013] Loss: 0.0116 Acc:99.09% Time:0.3721s
Training:Epoch[028/030] Iteration[008/013] Loss: 0.0094 Acc:99.22% Time:0.3898s
Training:Epoch[028/030] Iteration[010/013] Loss: 0.0282 Acc:99.06% Time:0.3806s
Training:Epoch[028/030] Iteration[012/013] Loss: 0.0100 Acc:99.15% Time:0.3931s
Test:	 Epoch[028/030] Iteration[004/004] Acc:93.91%

The learning rate for epoch 28 is [0.001782, 0.001673, 0.001235, 0.001068, 0.001046, 0.001155, 0.00108, 0.001101, 0.000999, 0.008267]
Training:Epoch[029/030] Iteration[002/013] Loss: 0.0324 Acc:98.44% Time:0.3857s
Training:Epoch[029/030] Iteration[004/013] Loss: 0.0225 Acc:98.63% Time:0.3855s
Training:Epoch[029/030] Iteration[006/013] Loss: 0.0193 Acc:98.70% Time:0.3689s
Training:Epoch[029/030] Iteration[008/013] Loss: 0.0163 Acc:98.93% Time:0.4202s
Training:Epoch[029/030] Iteration[010/013] Loss: 0.0349 Acc:98.83% Time:0.3688s
Training:Epoch[029/030] Iteration[012/013] Loss: 0.0037 Acc:99.02% Time:0.3827s
Test:	 Epoch[029/030] Iteration[004/004] Acc:89.71%

The learning rate for epoch 29 is [0.001833, 0.001674, 0.001242, 0.001082, 0.001052, 0.001159, 0.00108, 0.001102, 0.001001, 0.008046]
Training:Epoch[030/030] Iteration[002/013] Loss: 0.0030 Acc:100.00% Time:0.3724s
Training:Epoch[030/030] Iteration[004/013] Loss: 0.0189 Acc:99.61% Time:0.3902s
Training:Epoch[030/030] Iteration[006/013] Loss: 0.0094 Acc:99.48% Time:0.3849s
Training:Epoch[030/030] Iteration[008/013] Loss: 0.0242 Acc:99.22% Time:0.3946s
Training:Epoch[030/030] Iteration[010/013] Loss: 0.0221 Acc:99.30% Time:0.3740s
Training:Epoch[030/030] Iteration[012/013] Loss: 0.0081 Acc:99.41% Time:0.3855s
Test:	 Epoch[030/030] Iteration[004/004] Acc:88.03%

The learning rate for epoch 30 is [0.001842, 0.00168, 0.001238, 0.001081, 0.001045, 0.001157, 0.00108, 0.001101, 0.001001, 0.008104]

Training finish, the time consumption of 30 epochs is 231s

The max testing accuracy is: 93.91%, reached at epoch 28.


The confusion matrix is:
[[ 579   17   59]
 [   7  336    6]
 [  27   10 1075]]

The precision of class 0 is: 0.9445350734094616
The precision of class 1 is: 0.9256198347107438
The precision of class 2 is: 0.9429824561403509

The recall of class 0 is: 0.8839694656488549
The recall of class 1 is: 0.9627507163323782
The recall of class 2 is: 0.966726618705036

Total acc is: 94.05
